{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.1 Exploring the green reds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter_matrix(wine_data, good_threshhold, bad_threshold, save_plot=False):\n",
    "    \"\"\"Visualizes the data\n",
    "    \"\"\"\n",
    "    length = len(wine_data.columns)\n",
    "    fig, ax = plt.subplots(length, length, figsize=(50, 50))\n",
    "    bigger = wine_data.where(wine_data['quality'] > good_threshhold)\n",
    "    smaller = wine_data.where(wine_data['quality'] < bad_threshold)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if i == j:\n",
    "                ax[(i, j)].text(0.5, 0.5, '\\n'.join(wine_data.columns[i].split()), fontsize=35, ha='center', va='center')\n",
    "            else:\n",
    "                ax[(j, i)].plot(bigger.iloc[:, i], bigger.iloc[:, j], 'co')\n",
    "                ax[(j, i)].plot(smaller.iloc[:, i], smaller.iloc[:, j], 'mo')\n",
    "    if save_plot:\n",
    "        plt.savefig('scatter_matrix.png')\n",
    "# plot_scatter_matrix(red_wine, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_scatter_matrix(red_wine, 7, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "I think it can be pH, sulphates, alcohol and total sulfur dioxide. Cause there\n",
    "different\n",
    "groups of wine(based on quality) r better splitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.2 Learning to perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3_8 = red_wine[(red_wine['quality'] >= 8) | (red_wine['quality'] <= 3)].reset_index(drop=True)\n",
    "y_3_8 = [1 if i == True else 0 for i in data_3_8['quality'] >= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('final weights = ', ret[-1][2], ', bias = ', ret[-1][3])\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('weights change = ', ret[-1][2][0] - ret[-detail - 1][2][0], ret[-1][2][1] - ret[-detail - 1][2][1])\n",
    "        print('weights = ', ret[-1][2], 'bias = ', ret[-1][3])\n",
    "        print('bias change = ', ret[-1][3] - ret[-detail - 1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron:\n",
    "    \"\"\"A simple perceptron, with randomly initialized weights and bias\"\"\"\n",
    "\n",
    "    def __init__(self, amount):\n",
    "        \"\"\"Random data initialization\"\"\"\n",
    "        random.seed(42)\n",
    "        self.amount = amount\n",
    "        self.weights = [random.random() for n in range(amount)]\n",
    "        self.bias = random.random()\n",
    "        for i in range(amount):\n",
    "            print('Weights[', i, '] = ', self.weights[i], sep='')\n",
    "        print('bias = ', self.bias, '\\n')\n",
    "\n",
    "    def activation(self, value):\n",
    "        \"\"\"Activation function\"\"\"\n",
    "        return 1 if value > 0 else 0\n",
    "\n",
    "    def predict(self, data, alpha = None, y = None):\n",
    "        \"\"\"Predicts answer and updates weights to fit the data item better\n",
    "        Returns predicted value or whether he guessed right\n",
    "        \"\"\"\n",
    "        rez = self.activation(sum([data[i] * self.weights[i]\n",
    "                                   for i in range(self.amount)]) + self.bias)\n",
    "        if y == None:\n",
    "            return rez\n",
    "        if rez != y:\n",
    "            self.weights = [self.weights[i] + alpha * data[i] * (y - rez) \n",
    "                            for i in range(self.amount)]\n",
    "            self.bias = self.bias + alpha * (y - rez)\n",
    "        return rez != y\n",
    "\n",
    "    def train(self, data, y, epochs = 0, alpha = 0.001):\n",
    "        \"\"\"Trains perceptron epoch times, and logs results\"\"\"\n",
    "        ret = []\n",
    "        errors = 1\n",
    "        if epochs == 0:\n",
    "            i = 0\n",
    "            while (errors):\n",
    "                errors = 0\n",
    "                for item in data.itertuples():\n",
    "                    errors += self.predict(item[1:], alpha, y[item[0]])\n",
    "                ret.append([i, errors, self.weights, self.bias])\n",
    "                i += 1\n",
    "                display(ret)\n",
    "            display(ret, final=True)\n",
    "        else:\n",
    "            for i in range(epochs):\n",
    "                errors = 0\n",
    "                for item in data.itertuples():\n",
    "                    errors += self.predict(item[1:], alpha, y[item[0]])\n",
    "                ret.append([i, errors, self.weights, self.bias])\n",
    "                display(ret)\n",
    "                if errors == 0:\n",
    "                    break\n",
    "            display(ret, final=True)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.6394267984578837\n",
      "Weights[1] = 0.025010755222666936\n",
      "bias =  0.27502931836911926 \n",
      "\n",
      "....................................................................................................\n",
      "cycle = 10000, errors = 2\n",
      "weights change =  -7.069099999996053 1.848000000000045\n",
      "weights =  [-6.536073201538169, 1.653510755222712] bias =  4.455029318369069\n",
      "bias change =  4.209999999999949\n",
      "...............................\n",
      "DONE\n",
      "cycle = 13154, errors = 0\n",
      "final weights =  [-7.259373201536793, 1.731510755222712] , bias =  6.135029318369033\n"
     ]
    }
   ],
   "source": [
    "model = perceptron(2)\n",
    "logs = model.train(data_3_8[['pH', 'alcohol']], y_3_8, 0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(performance, wine_data, good_threshold, bad_threshold, epoch=-1, save_plot=False, debug=False):\n",
    "    \"\"\"Plot the performance of my perceptron\"\"\"\n",
    "    if debug:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 2)#, figsize=(10, 10))\n",
    "    bigger = wine_data.where(wine_data['quality'] > good_threshold).reset_index(drop=True)\n",
    "    smaller = wine_data.where(wine_data['quality'] < bad_threshold).reset_index(drop=True)\n",
    "    \n",
    "    ax[0].plot([i[1] for i in performance], 'g')\n",
    "    ax[0].set_title('Errors as a function of epoch')\n",
    "    ax[0].set_ylabel('Classification errors')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[1].plot(bigger['alcohol'], bigger['pH'], 'mo', label = 'good wines (> ' + str(good_threshold) + ' score)')\n",
    "    ax[1].plot(smaller['alcohol'], smaller['pH'], 'co', label = 'bad wines (< ' + str(bad_threshold) + ' score)')\n",
    "    ax[1].set_title('Decision boundary on epoch:' + str(len(performance) if epoch == -1 else epoch))\n",
    "    ax[1].set_xlabel('Alcohol')\n",
    "    ax[1].set_ylabel('pH')\n",
    "    \n",
    "    val = {}\n",
    "    if debug:\n",
    "        val['alcohol'] = [-100, 100]         \n",
    "    else:\n",
    "#         val['alcohol'] = [5, 15]         \n",
    "        val['alcohol'] = [min(wine_data['alcohol']) - 1, max(wine_data['alcohol']) + 1] \n",
    "    val['pH'] = [\n",
    "            - (performance[epoch][2][1] * val['alcohol'][0] + performance[epoch][3]) / performance[epoch][2][0],\n",
    "            - (performance[epoch][2][1] * val['alcohol'][1] + performance[epoch][3]) / performance[epoch][2][0]\n",
    "        ]\n",
    "    ax[1].plot(val['alcohol'], val['pH'], 'g--')\n",
    "    if debug:\n",
    "        ax[1].set_xlim(-100, 100)\n",
    "        ax[1].set_ylim(-100, 100)\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], -100, facecolor='#f8bbd0')\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], 100, facecolor='#b2ebf2')\n",
    "    else:\n",
    "#         ax[1].set_xlim(5, 15)\n",
    "#         ax[1].set_ylim(2, 5)\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], -5, facecolor='#f8bbd0')\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], 15, facecolor='#b2ebf2')\n",
    "        ax[1].set_xlim(min(wine_data['alcohol']) - 1, max(wine_data['alcohol']) + 1)\n",
    "        ax[1].set_ylim(min(wine_data['pH']) - 1, max(wine_data['pH']) + 1)\n",
    "#         ax[1].fill_between(val['alcohol'], val['pH'], min(wine_data['pH']), facecolor='#b2ebf2')\n",
    "#         ax[1].fill_between(val['alcohol'], val['pH'], max(wine_data['pH']), facecolor='#f8bbd0')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(1.6, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00249393b3f4137aefa9eca298036d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(logs), wine_data=fixed(red_wine), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(logs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalized_red_wine = red_wine.copy()\n",
    "for title in red_wine.columns:\n",
    "    if not title == 'quality':\n",
    "        normalized_red_wine[title] = (red_wine[title] - min(red_wine[title])) / (max(red_wine[title]) - min(red_wine[title]))\n",
    "normalized_data_3_8 = normalized_red_wine[(red_wine['quality'] >= 8) | (red_wine['quality'] <= 3)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.6394267984578837\n",
      "Weights[1] = 0.025010755222666936\n",
      "bias =  0.27502931836911926 \n",
      "\n",
      "\n",
      "DONE\n",
      "cycle = 85, errors = 0\n",
      "final weights =  [-0.09521887083345507, 0.10070306291497405] , bias =  0.015029318369119145\n"
     ]
    }
   ],
   "source": [
    "model_normalized = perceptron(2)\n",
    "logs_normalized = model_normalized.train(normalized_data_3_8[['pH', 'alcohol']], y_3_8, 0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4d642a81f944629a97a48eb7687990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(logs_normalized), wine_data=fixed(normalized_red_wine), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(logs_normalized) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.3 My fair ADALINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stochastic learning algorithm instead of batch. Not adding polynomial features and not using more complicated algorhithms. No parallelism. Using only labels in learning, not values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaline:\n",
    "    \"\"\"A simple adaline, with randomly initialized weights and bias\"\"\"\n",
    "\n",
    "    def __init__(self, amount):\n",
    "        \"\"\"Random data initialization\"\"\"\n",
    "        self.amount = amount\n",
    "        self.weights = [random.random() for n in range(amount)]\n",
    "        self.bias = random.random()\n",
    "\n",
    "        \n",
    "    def quantizer(self, value):\n",
    "        \"\"\"Quantizer function\"\"\"\n",
    "        return 1 if value > 6.35 else 0\n",
    "\n",
    "    \n",
    "    def predict(self, data, y=False):\n",
    "        \"\"\"Predicts answer and updates weights to fit the data item better\n",
    "        Returns predicted value or whether he guessed right\n",
    "        \"\"\"\n",
    "        rez = sum([data[i] * self.weights[i] for i in range(self.amount)]) + self.bias\n",
    "        if y == False:\n",
    "            return self.quantizer(rez)\n",
    "        else:\n",
    "            err = y - rez\n",
    "#             print('y =', y, 'rez =', rez, 'y - rez =', y - rez)\n",
    "            return [[x * err for x in [*data, 1]], err]\n",
    "        \n",
    "    def train(self, data, y, epochs = 0, alpha = 0.001):\n",
    "        \"\"\"Trains perceptron epoch times, and logs results\"\"\"\n",
    "        ret = []\n",
    "        if epochs == 0:\n",
    "            i = 0\n",
    "            while (True):\n",
    "                error = 0\n",
    "                delta = [0] * (self.amount + 1)\n",
    "                for item in data.itertuples():\n",
    "                    [rez, err] = self.predict(item[1:], y[item[0]])\n",
    "                    delta = [delta[i] + rez[i] for i in range(self.amount + 1)]\n",
    "                    error += err\n",
    "                self.weights = [self.weights[i] + alpha * delta[i] / len(data) for i in range(self.amount)]\n",
    "                self.bias += alpha * delta[-1] / len(data)\n",
    "                ret.append([i, error, self.weights, self.bias - 5])\n",
    "                display(ret)\n",
    "                if i > 0 and abs(ret[-1][1] - error) < 0.001:\n",
    "                    break\n",
    "                i += 1\n",
    "            display(ret, final=True)\n",
    "        else:\n",
    "            for i in range(epochs):\n",
    "                error = 0\n",
    "                delta = [0] * (self.amount + 1)\n",
    "                for item in data.itertuples():\n",
    "                    [rez, err] = self.predict(item[1:], y[item[0]])\n",
    "                    delta = [delta[i] + rez[i] for i in range(self.amount + 1)]\n",
    "                    error += err ** 2\n",
    "#                 print(delta, errors)\n",
    "                self.weights = [self.weights[i] + alpha * delta[i] / len(data) for i in range(self.amount)]\n",
    "                self.bias += alpha * delta[-1] / len(data)\n",
    "                ret.append([i, error, self.weights, self.bias - 5])\n",
    "                display(ret)\n",
    "                if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                    print(ret[-1], error)\n",
    "                    break\n",
    "            display(ret, final=True)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_7 = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index(drop=True)\n",
    "y_4_7 = data_4_7['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0661c1f54550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madaline_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_4_7\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pH'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alcohol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_4_7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-20b1cc96d034>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, y, epochs, alpha)\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0mrez\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrez\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamount\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-20b1cc96d034>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, y)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrez\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#             print('y =', y, 'rez =', rez, 'y - rez =', y - rez)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = adaline(2)\n",
    "adaline_logs = model.train(data_4_7[['pH', 'alcohol']], y_4_7.tolist(), 30000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55994258052c4ce785d89934866cfedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(adaline_logs), wine_data=fixed(data_4_7), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(adaline_logs) - 1), debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_4_7 = normalized_red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................[8269, 329.962429384063, [-4.00187175480784, 4.712259290917971], 1.1024108563495156] 329.962429384063\n",
      "\n",
      "DONE\n",
      "cycle = 8269, errors = 329.962429384063\n",
      "final weights =  [-4.00187175480784, 4.712259290917971] , bias =  1.1024108563495156\n"
     ]
    }
   ],
   "source": [
    "model = adaline(2)\n",
    "adaline_logs_normalized = model.train(normalized_data_4_7[['pH', 'alcohol']], y_4_7.tolist(), 30000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5321428571428571\n",
      "68 / 280\n"
     ]
    }
   ],
   "source": [
    "pred = [model.predict(normalized_data_4_7.loc[i, ['pH', 'alcohol']]) for i in range(len(normalized_data_4_7))]\n",
    "y = [1 if i == True else 0 for i in normalized_data_4_7['quality'] >= 7]\n",
    "\n",
    "print(s)\n",
    "print(sum([(y[i] - pred[i]) for i in range(len(y))]), '/', len(normalized_data_4_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f96e467828347b18c3f34fd371d4c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(adaline_logs_normalized), wine_data=fixed(normalized_data_4_7), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(adaline_logs_normalized) - 1), debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(input_data, percentage=30):\n",
    "    data = input_data.sample(frac=1).reset_index(drop=True)\n",
    "    sep = int(len(data) * percentage / 100)\n",
    "    return (data[:sep], data[sep:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 84 196\n"
     ]
    }
   ],
   "source": [
    "train, test = holdout(normalized_data_4_7)\n",
    "print(len(normalized_data_4_7), len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(input_data, k=10, shuffle=False):\n",
    "    data = input_data.sample(frac=1).reset_index(drop=True) if shuffle else input_data\n",
    "    seps = [int(len(data) / k) * i for i in range(k + 1)]\n",
    "    parts = []\n",
    "    print(len(seps))\n",
    "    for i in range(k):\n",
    "        parts.append(data[seps[i]:seps[i + 1]])\n",
    "    ret = []\n",
    "    for i in range(k):\n",
    "        train = pd.concat([parts[j] for j in range(k) if not j == i])\n",
    "        test = parts[i]\n",
    "        ret.append((train, test))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n"
     ]
    }
   ],
   "source": [
    "data = k_folds(normalized_data_4_7)\n",
    "for train, test in data:\n",
    "    print(len(normalized_data_4_7), len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(input_data, y, k=10, epochs=10000, alpha=10):\n",
    "    data = k_folds(input_data)\n",
    "    error = []\n",
    "    logs = []\n",
    "    for train, test in data:\n",
    "        model = adaline(2)\n",
    "        log = model.train(train[['pH', 'alcohol']], train['quality'].tolist(), epochs, alpha)\n",
    "        logs.append(log)\n",
    "        y = [1 if i == True else 0 for i in train['quality'] >= 7]\n",
    "        pred = [model.predict(train.loc[i, ['pH', 'alcohol']]) for i in range(len(train))]\n",
    "        error.append(sum([abs(y[i] - pred[i]) for i in range(len(y))]))\n",
    "    return (sum(error) / k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.5 Adventures in the Nth dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.6394267984578837\n",
      "Weights[1] = 0.025010755222666936\n",
      "Weights[2] = 0.27502931836911926\n",
      "Weights[3] = 0.22321073814882275\n",
      "Weights[4] = 0.7364712141640124\n",
      "Weights[5] = 0.6766994874229113\n",
      "Weights[6] = 0.8921795677048454\n",
      "Weights[7] = 0.08693883262941615\n",
      "Weights[8] = 0.4219218196852704\n",
      "Weights[9] = 0.029797219438070344\n",
      "Weights[10] = 0.21863797480360336\n",
      "bias =  0.5053552881033624 \n",
      "\n",
      "............................................................"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b86e7efd4df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m adaline_logs = model.train(normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m'chlorides'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'free sulfur dioxide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total sulfur dioxide'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'density'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m        'pH', 'sulphates', 'alcohol']], y_4_7, 30000, 0.01)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-46e5f2ee699a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, y, epochs, alpha)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0merrors\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3115\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'getitem'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/pandas/core/indexes/numeric.py\u001b[0m in \u001b[0;36m_convert_scalar_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'iloc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         return (super(Int64Index, self)\n\u001b[0m\u001b[1;32m    187\u001b[0m                 ._convert_scalar_indexer(key, kind=kind))\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = perceptron(11)\n",
    "adaline_logs = model.train(normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']], y_4_7, 30000, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It converges when data is separable in that hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's called a hyperplane. For 2-dimensional space it's a point, for 3-d it's line and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V.6 Marvin's rebuttal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pan_gal = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_to_poly(data):\n",
    "    poly = data.values.tolist()\n",
    "    length = len(tmp[0])\n",
    "    for line in pan_gal_poly:\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                line.append(line[i] * line[j])\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                for k in range(length):\n",
    "                    line.append(line[i] * line[j] * line[k])\n",
    "    print('Was:', length, 'Now:', len(pan_gal_poly[0]))\n",
    "    return poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "1884\n"
     ]
    }
   ],
   "source": [
    "pan_gal_poly = pan_gal.values.tolist()\n",
    "length = len(tmp[0])\n",
    "print(length)\n",
    "for line in pan_gal_poly:\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            line.append(line[i] * line[j])\n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            for k in range(length):\n",
    "                line.append(line[i] * line[j] * line[k])\n",
    "print(len(pan_gal_poly[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.5245871020129822\n",
      "Weights[1] = 0.7354235321913956\n",
      "Weights[2] = 0.26330554078487006\n",
      "Weights[3] = 0.37622397131110724\n",
      "Weights[4] = 0.19628582577979464\n",
      "Weights[5] = 0.9758738810084173\n",
      "Weights[6] = 0.512318108469396\n",
      "Weights[7] = 0.5304490451377114\n",
      "Weights[8] = 0.2571016295147602\n",
      "Weights[9] = 0.10708725457409735\n",
      "Weights[10] = 0.8154876268540917\n",
      "bias =  0.00032870750889587566 \n",
      "\n",
      "....................................................................................................\n",
      "cycle = 10000, errors = 52.0\n",
      "weights change =  -0.5166780499996315 -0.030206160497907253\n",
      "weights =  [0.0076829020133507295, 0.7052047711934891, 0.24497983478481788, 0.205816976311079, 0.1910769797798061, 0.5048138810071049, -0.5172696915334013, 0.469923194115813, 0.05521953151586182, 0.06848433557434076, 0.13773986185549209] bias =  -0.06043809249181213\n",
      "bias change =  -0.06074060000070801\n",
      "....................................................................................................\n",
      "cycle = 20000, errors = 38.0\n",
      "weights change =  -0.08498692999990387 -0.009098968999763257\n",
      "weights =  [-0.07730402798655314, 0.6961058021937259, 0.24558873678457394, 0.16899629631144664, 0.18972908337975541, 0.476014981007899, -0.3474250915347431, 0.45756855659450313, 0.012283758515909383, 0.06400915957431949, 0.012758611855517205] bias =  -0.07284609249216893\n",
      "bias change =  -0.0124080000003568\n",
      "....................................................................................................\n",
      "cycle = 30000, errors = 35.0\n",
      "weights change =  -0.009722059999607485 -0.005819418998860293\n",
      "weights =  [-0.08702608798616063, 0.6902863831948656, 0.24966247478478182, 0.15645749631173156, 0.18907975397904814, 0.3649457810093812, -0.25842249153665287, 0.4540193059128784, -0.0020177714840941036, 0.0642517175741989, -0.008840748144482387] bias =  -0.07640349249227123\n",
      "bias change =  -0.0035574000001022954\n",
      "....................................................................................................\n",
      "cycle = 40000, errors = 34.0\n",
      "weights change =  0.0011589700003604986 -0.0057607619980668545\n",
      "weights =  [-0.08586711798580013, 0.6845256211967987, 0.25425916578531743, 0.14489616631209806, 0.1885921836785773, 0.2502097810110826, -0.17588549153722788, 0.45148676444337393, -0.013070557484105181, 0.06524595157404318, -0.021078148144491746] bias =  -0.07894089249234419\n",
      "bias change =  -0.0025374000000729646\n",
      "....................................................................................................\n",
      "cycle = 50000, errors = 37.0\n",
      "weights change =  0.004836590000359686 -0.006345958997036716\n",
      "weights =  [-0.08103052798544044, 0.678179662199762, 0.25892072378565056, 0.125796586312556, 0.188162769278617, 0.1409780810108209, -0.0958276915375224, 0.4489768941787955, -0.024340225484039454, 0.06631462157383547, -0.03642017814451564] bias =  -0.08145579249241651\n",
      "bias change =  -0.0025149000000723176\n",
      "....................................................................................................\n",
      "cycle = 60000, errors = 37.0\n",
      "weights change =  0.006666610000284914 -0.008781863996821238\n",
      "weights =  [-0.07436391798515553, 0.6693977982029408, 0.26437822778569076, 0.09899327631230338, 0.18770103847894798, 0.045861481010823, -0.027220791537532117, 0.4461939119812267, -0.0373027064840336, 0.06756676657368071, -0.053426268144515635] bias =  -0.08424059249249659\n",
      "bias change =  -0.0027848000000800788\n",
      "....................................................................................................\n",
      "cycle = 70000, errors = 38.0\n",
      "weights change =  0.012591350000177137 -0.009799344496139839\n",
      "weights =  [-0.06177256798497839, 0.6595984537068009, 0.2691499047854115, 0.06601797631199942, 0.18677786277942196, 0.005036281010849196, -0.004319291537514801, 0.4443569059819602, -0.04674385648414012, 0.06890436557354314, -0.050247048144462625] bias =  -0.08606399249254902\n",
      "bias change =  -0.001823400000052433\n",
      "....................................................................................................\n",
      "cycle = 80000, errors = 39.0\n",
      "weights change =  0.010035689999995275 -0.011351333996635682\n",
      "weights =  [-0.051736877984983116, 0.6482471197101652, 0.27384669478534235, 0.04170641631200853, 0.18570829897959454, 0.001274081010845757, -0.001969891537501004, 0.44215490059232054, -0.05725330248419467, 0.07038513457344664, -0.0458979481443848] bias =  -0.088253992492612\n",
      "bias change =  -0.002190000000062975\n",
      "....................................................................................................\n",
      "cycle = 90000, errors = 38.0\n",
      "weights change =  0.0064518400000237106 -0.012348637996746459\n",
      "weights =  [-0.045285037984959406, 0.6358984817134188, 0.27867052578486134, 0.027465056312028013, 0.18461317117966455, -0.0015421189891555258, -0.0006554915374989556, 0.4396821685718424, -0.06864394448426264, 0.0719975245733518, -0.041708268144292376] bias =  -0.0907163924926828\n",
      "bias change =  -0.002462400000070808\n",
      "....................................................................................................\n",
      "cycle = 100000, errors = 39.0\n",
      "weights change =  0.0047250299999954115 -0.012597126997204278\n",
      "weights =  [-0.040560007984963994, 0.6233013547162145, 0.28335033978411245, 0.01794531631197233, 0.18352147697975363, -0.0020724189891483057, -0.0007017915374972486, 0.4371401982032814, -0.0801376884843506, 0.07373425057326126, -0.037515338144175604] bias =  -0.09324909249275563\n",
      "bias change =  -0.0025327000000728295\n",
      "....................................................................................................\n",
      "cycle = 110000, errors = 39.0\n",
      "weights change =  0.003312279999953399 -0.012694423997346438\n",
      "weights =  [-0.037247727985010595, 0.6106069307188681, 0.2880039647835417, 0.011651326311954237, 0.1822738827798257, -0.001294818989152033, -0.0007841915374960626, 0.4344310934076167, -0.09201127848442646, 0.07538571957316877, -0.03388608814403849] bias =  -0.09595049249283331\n",
      "bias change =  -0.0027014000000776806\n",
      "....................................................................................................\n",
      "cycle = 120000, errors = 39.0\n",
      "weights change =  0.0030682999999322447 -0.012501627997915987\n",
      "weights =  [-0.03417942798507835, 0.5981053027209521, 0.29225469278277544, 0.008018526311954342, 0.1809710907798186, -8.541898915314409e-05, -0.0011059915374941806, 0.43170511501473935, -0.10383775248453565, 0.0770390815730705, -0.029551168143966196] bias =  -0.09866909249291149\n",
      "bias change =  -0.002718600000078175\n",
      "....................................................................................................\n",
      "cycle = 130000, errors = 38.0\n",
      "weights change =  0.002577579999932203 -0.012520441997956655\n",
      "weights =  [-0.03160184798514615, 0.5855848607229954, 0.29647768278201014, 0.004319396311976897, 0.17965722757981684, 0.001025781010846506, -0.0012874915374916523, 0.4289386899178589, -0.11578744148464605, 0.07866386857297607, -0.025508508143971174] bias =  -0.10142809249299083\n",
      "bias change =  -0.002759000000079337\n",
      "....................................................................................................\n",
      "cycle = 140000, errors = 39.0\n",
      "weights change =  0.002014319999893849 -0.01254208799800327\n",
      "weights =  [-0.0295875279852523, 0.5730427727249922, 0.3006688307812459, 0.0005443263119746151, 0.1783306715798212, 0.0020225810108437186, -0.0013207915374891255, 0.42612581173297487, -0.1278786564847248, 0.08025587157288601, -0.021801648143974735] bias =  -0.1042334924930715\n",
      "bias change =  -0.002805400000080671\n",
      "....................................................................................................\n",
      "cycle = 150000, errors = 39.0\n",
      "weights change =  0.0015371599998863332 -0.012474523998051823\n",
      "weights =  [-0.028050367985365966, 0.5605682487269403, 0.3047784447805302, -0.0024440436880285928, 0.17698351317987082, 0.0027187810108508493, -0.0013504915374868238, 0.42333284269204463, -0.139856147484724, 0.08183755257280699, -0.017550068143973585] bias =  -0.10701869249315159\n",
      "bias change =  -0.0027852000000800903\n",
      "....................................................................................................\n",
      "cycle = 160000, errors = 39.0\n",
      "weights change =  0.00019223999988731214 -0.012251541998248405\n",
      "weights =  [-0.027858127985478653, 0.5483167067286919, 0.308628684779971, -0.003459513688038401, 0.17556802598005777, 0.0027205810108570506, -0.0014383915374850955, 0.4206109913229716, -0.15145145248480413, 0.08336399157275819, -0.011637468143982086] bias =  -0.1097316924932296\n",
      "bias change =  -0.002713000000078014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 170000, errors = 39.0\n",
      "weights change =  -0.0001911400001075418 -0.012080730498363224\n",
      "weights =  [-0.028049267985586195, 0.5362359762303287, 0.31229471977953144, -0.004972093688023844, 0.17413418418028015, 0.0026872810108627154, -0.0014919915374832502, 0.4179699836298492, -0.16267707248494312, 0.08478198757270573, -0.005597318143986204] bias =  -0.11236319249330527\n",
      "bias change =  -0.0026315000000756705\n",
      "....................................................................................................\n",
      "cycle = 180000, errors = 39.0\n",
      "weights change =  0.0001757299999112054 -0.011562584998146996\n",
      "weights =  [-0.02787353798567499, 0.5246733912321817, 0.3154959147793092, -0.0075607136879988854, 0.17266242758052583, 0.0016234810108658234, -0.0013255915374809839, 0.41558026383270014, -0.17286467148520998, 0.08583626657261921, -0.00033686814398074447] bias =  -0.11474339249337372\n",
      "bias change =  -0.0023802000000684442\n",
      "....................................................................................................\n",
      "cycle = 190000, errors = 39.0\n",
      "weights change =  -0.0005948200000943198 -0.011645207997873053\n",
      "weights =  [-0.02846835798576931, 0.5130281832343087, 0.31878087777917036, -0.010131833687994814, 0.17129818118069437, 0.0004449810108642071, -0.0009880915374794142, 0.4132991204034853, -0.18267129848549502, 0.08699440257253126, 0.004430751856021838] bias =  -0.11701409249343901\n",
      "bias change =  -0.0022707000000652955\n",
      "....................................................................................................\n",
      "cycle = 200000, errors = 38.0\n",
      "weights change =  -0.00033447000009249536 -0.011537514497807377\n",
      "weights =  [-0.028802827985861805, 0.5014906687365013, 0.32200432477908636, -0.012773173687991092, 0.16993265978088404, -0.00021851898913616947, -0.0008285915374774283, 0.4110887705222891, -0.1922244934857972, 0.08812075457245788, 0.009464651856034609] bias =  -0.11921339249350225\n",
      "bias change =  -0.0021993000000632423\n",
      "....................................................................................................\n",
      "cycle = 210000, errors = 38.0\n",
      "weights change =  -0.0003426500000786592 -0.010830783501178665\n",
      "weights =  [-0.029145477985940464, 0.4906598852353226, 0.32462854577905476, -0.014920053687980597, 0.16856569618118455, 0.0003865810108637784, -0.0008862915374753992, 0.4090748720362934, -0.20091666448621515, 0.08890613257238827, 0.012919621856013383] bias =  -0.12121669249355986\n",
      "bias change =  -0.0020033000000576062\n",
      "....................................................................................................\n",
      "cycle = 220000, errors = 37.0\n",
      "weights change =  -0.00021822000007603454 -0.010313629501676469\n",
      "weights =  [-0.0293636979860165, 0.48034625573364614, 0.32683697777888177, -0.01593017368799854, 0.16721270298152863, 0.0015238810108626059, -0.0008275915374732374, 0.40719575534162306, -0.20902728148668953, 0.08957043757227075, 0.015402481855995213] bias =  -0.12308679249361364\n",
      "bias change =  -0.001870100000053776\n",
      "....................................................................................................\n",
      "cycle = 230000, errors = 36.0\n",
      "weights change =  0.00010498999992238772 -0.009971940001700708\n",
      "weights =  [-0.02925870798609411, 0.47037431573194544, 0.32884062277863596, -0.016640293688072384, 0.16588394908186832, 0.001594881010861071, -0.0008769915374710773, 0.40550820248902175, -0.2163871084871883, 0.09028038357210785, 0.018788841856035368] bias =  -0.12476449249366188\n",
      "bias change =  -0.0016777000000482434\n",
      "....................................................................................................\n",
      "cycle = 240000, errors = 35.0\n",
      "weights change =  -0.00038170000008889635 -0.009364956001841396\n",
      "weights =  [-0.029640407986183007, 0.46100935973010404, 0.33036817277853026, -0.01818164368815772, 0.16472535588219944, 0.001693081010859896, -0.0008368915374688695, 0.4040523144993529, -0.22269419748769012, 0.0909062135718721, 0.02130260185607614] bias =  -0.12621159249370348\n",
      "bias change =  -0.0014471000000415984\n",
      "....................................................................................................\n",
      "cycle = 250000, errors = 35.0\n",
      "weights change =  -0.000457270000095298 -0.00905866900193758\n",
      "weights =  [-0.030097677986278305, 0.45195069072816646, 0.3317218797784489, -0.018999853688249947, 0.16358260958248672, 0.0016674810108591879, -0.0008735915374664015, 0.40269027359365234, -0.2285248794881785, 0.09151907557163026, 0.024268541856108737] bias =  -0.12756459249374238\n",
      "bias change =  -0.0013530000000389064\n",
      "....................................................................................................\n",
      "cycle = 260000, errors = 35.0\n",
      "weights change =  -0.0013800800000825508 -0.008274839002050782\n",
      "weights =  [-0.031477757986360856, 0.4436758517261157, 0.332532335778535, -0.018594063688346395, 0.16246182658270591, 0.0018176810108598218, -0.0009394915374636816, 0.40152818371788107, -0.2333774714886946, 0.09200412257137053, 0.02712295185612092] bias =  -0.12871739249377553\n",
      "bias change =  -0.0011528000000331495\n",
      "....................................................................................................\n",
      "cycle = 270000, errors = 32.0\n",
      "weights change =  -0.000882280000023411 -0.007756048502173096\n",
      "weights =  [-0.03236003798638427, 0.4359198032239426, 0.3329655767787195, -0.019444943688438833, 0.16141081348299244, 0.0018751810108610819, -0.0010248915374626274, 0.40061240289696903, -0.2373817444892869, 0.09260642557100839, 0.029838681856140938] bias =  -0.12962309249380158\n",
      "bias change =  -0.000905700000026044\n",
      "....................................................................................................\n",
      "cycle = 280000, errors = 33.0\n",
      "weights change =  -0.0009851000000361126 -0.007568238002126193\n",
      "weights =  [-0.03334513798642038, 0.4283515652218164, 0.33326726377888277, -0.020679763688536006, 0.16039085618326276, 0.0020919810108631794, -0.0011536915374638819, 0.3997972254959861, -0.24100434048991518, 0.09324368357061075, 0.03271651185608668] bias =  -0.1304273924938247\n",
      "bias change =  -0.0008043000000231282\n",
      "....................................................................................................\n",
      "cycle = 290000, errors = 31.0\n",
      "weights change =  -0.0004365900000324052 -0.007548944502182686\n",
      "weights =  [-0.033781727986452785, 0.4208026207196337, 0.33365577877891706, -0.021880003688632868, 0.15938056128360176, 0.0023299810108663986, -0.0012314915374644396, 0.39897227167495997, -0.24466372449059298, 0.09386985157022308, 0.03486164185597516] bias =  -0.13124219249384814\n",
      "bias change =  -0.0008148000000234301\n",
      "....................................................................................................\n",
      "cycle = 300000, errors = 33.0\n",
      "weights change =  0.0005911799999736983 -0.007524460002281241\n",
      "weights =  [-0.03319054798647909, 0.41327816071735246, 0.3342054387787273, -0.023014043688729637, 0.1583876113840571, 0.0025012810108698013, -0.0011685915374638224, 0.3981318881738505, -0.24839135749135666, 0.09448403956985295, 0.03577197185589647] bias =  -0.13207369249387205\n",
      "bias change =  -0.0008315000000239103\n",
      "....................................................................................................\n",
      "cycle = 310000, errors = 31.0\n",
      "weights change =  0.0006980899999755735 -0.007522929002275913\n",
      "weights =  [-0.03249245798650351, 0.40575523171507655, 0.3347768777785129, -0.02407305368882673, 0.15739522858451913, 0.002663081010873134, -0.0011088915374631253, 0.39729221473273163, -0.25211677549090106, 0.09509367256948718, 0.03662749185582086] bias =  -0.13290459249389594\n",
      "bias change =  -0.0008309000000238931\n",
      "....................................................................................................\n",
      "cycle = 320000, errors = 30.0\n",
      "weights change =  0.0009919499999812842 -0.007391897002190617\n",
      "weights =  [-0.03150050798652223, 0.39836333471288593, 0.3354196207783023, -0.025033793688924978, 0.15639302028499485, 0.0027922810108762606, -0.0010540915374621558, 0.39652738009264665, -0.2555576774894302, 0.09565042956913425, 0.03733872185574812] bias =  -0.1336609924939177\n",
      "bias change =  -0.0007564000000217508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 330000, errors = 30.0\n",
      "weights change =  0.0007593499999386626 -0.006722253001605005\n",
      "weights =  [-0.030741157986583566, 0.3916410817112809, 0.33603644077840156, -0.02572124368901778, 0.15534827088545966, 0.002914981010878705, -0.0009831915374615794, 0.39604703743779235, -0.2579115184878203, 0.09585060956884439, 0.0376399318556422] bias =  -0.13413359249393128\n",
      "bias change =  -0.0004726000000135899\n",
      "....................................................................................................\n",
      "cycle = 340000, errors = 30.0\n",
      "weights change =  -0.00034163000005702285 -0.005875533001448052\n",
      "weights =  [-0.03108278798664059, 0.3857655487098329, 0.3362131307784304, -0.0263344136891179, 0.15431962048591233, 0.002927681010879337, -0.0010279915374598514, 0.39581096836212776, -0.2590789884862303, 0.09594835956855972, 0.038888851855522856] bias =  -0.13435929249393777\n",
      "bias change =  -0.00022570000000649015\n",
      "....................................................................................................\n",
      "cycle = 350000, errors = 31.0\n",
      "weights change =  -0.0002923900000362731 -0.0053672080013802415\n",
      "weights =  [-0.03137517798667686, 0.38039834070845263, 0.33617233977858524, -0.026638313689214085, 0.1532878073862727, 0.0029007810108797336, -0.0010606915374585602, 0.39566268454460857, -0.2598009364846544, 0.09595998256826481, 0.03985413185540549] bias =  -0.13449759249394175\n",
      "bias change =  -0.0001383000000039769\n",
      "....................................................................................................\n",
      "cycle = 360000, errors = 32.0\n",
      "weights change =  0.00014431999996861525 -0.005095041001303369\n",
      "weights =  [-0.031230857986708247, 0.37530329970714926, 0.33604681677889386, -0.026549083689303702, 0.15226235888656356, 0.0029405810108794764, -0.0010356915374570973, 0.3955279398241313, -0.26045039848301305, 0.09586865456798459, 0.04012804185529689] bias =  -0.13462369249394537\n",
      "bias change =  -0.0001261000000036261\n",
      "....................................................................................................\n",
      "cycle = 370000, errors = 30.0\n",
      "weights change =  0.00014507999996555068 -0.005094958001303329\n",
      "weights =  [-0.031085777986742696, 0.37020834170584593, 0.3359212947792025, -0.026459533689393317, 0.15123691768685438, 0.0029855810108792196, -0.0010098915374556346, 0.3953932949036541, -0.2610995124813717, 0.09577735656770436, 0.04040312185518829] bias =  -0.134749692493949\n",
      "bias change =  -0.00012600000000362321\n",
      "....................................................................................................\n",
      "cycle = 380000, errors = 32.0\n",
      "weights change =  9.667999996527954e-05 -0.0050836540012991205\n",
      "weights =  [-0.030989097986777417, 0.3651246877045468, 0.3357870327795127, -0.026363563689483026, 0.15021104578714436, 0.0030157810108789353, -0.0009940915374542034, 0.3952617231121815, -0.26172879447973657, 0.09568660956742464, 0.040725461855078755] bias =  -0.13487259249395253\n",
      "bias change =  -0.00012290000000353407\n",
      "....................................................................................................\n",
      "cycle = 390000, errors = 30.0\n",
      "weights change =  -0.00041601000003618077 -0.00495990350125286\n",
      "weights =  [-0.0314051079868136, 0.36016478420329395, 0.33555806277984035, -0.026193633689573732, 0.14918060078742476, 0.0029922810108783584, -0.0010197915374531167, 0.3951652521387594, -0.2621369514781693, 0.0956023585671503, 0.04158113185495907] bias =  -0.13496009249395505\n",
      "bias change =  -8.750000000251612e-05\n",
      "....................................................................................................\n",
      "cycle = 400000, errors = 32.0\n",
      "weights change =  -0.00041568000003346095 -0.0049602610012529635\n",
      "weights =  [-0.03182078798684706, 0.355204523202041, 0.3353292877801679, -0.026024083689664437, 0.14815015948770519, 0.002964881010877782, -0.001053991537452029, 0.3950685825983372, -0.26254601347660184, 0.09551801856687595, 0.042434121854839406] bias =  -0.13504779249395757\n",
      "bias change =  -8.770000000252187e-05\n",
      "....................................................................................................\n",
      "cycle = 410000, errors = 30.0\n",
      "weights change =  -0.00045368000004224196 -0.004725725001186065\n",
      "weights =  [-0.0322744679868893, 0.3504787982008549, 0.3349710467806329, -0.02523737368974568, 0.14713244208796541, 0.0029406810108768182, -0.0010549915374511345, 0.3949558115268539, -0.26290311947512035, 0.09545207756657421, 0.04303987185471377] bias =  -0.1351533924939606\n",
      "bias change =  -0.0001056000000030366\n",
      "....................................................................................................\n",
      "cycle = 420000, errors = 28.0\n",
      "weights change =  -0.0005371300000493254 -0.0045304230011289914\n",
      "weights =  [-0.032811597986938626, 0.34594837519972593, 0.33450216978120645, -0.023963193689819685, 0.14612411748820878, 0.002932981010875524, -0.0010481915374504274, 0.3948344047743287, -0.2631959064737129, 0.0954009785662518, 0.043511691854582396] bias =  -0.13526899249396393\n",
      "bias change =  -0.00011560000000332415\n",
      "....................................................................................................\n",
      "cycle = 430000, errors = 27.0\n",
      "weights change =  -0.0005335200000494492 -0.004526041001125802\n",
      "weights =  [-0.033345117986988075, 0.34142233419860013, 0.3340320677817799, -0.02268535368989358, 0.1451158675884525, 0.002930081010874207, -0.0010546915374497158, 0.3947138969928031, -0.2634849724723045, 0.09534814756592966, 0.043983321854450745] bias =  -0.13538369249396723\n",
      "bias change =  -0.00011470000000329827\n",
      "....................................................................................................\n",
      "cycle = 440000, errors = 28.0\n",
      "weights change =  -0.00020230000008000792 -0.003964056000751448\n",
      "weights =  [-0.03354741798706808, 0.3374582781978487, 0.3333356397825306, -0.02156081368994976, 0.14410967918865672, 0.0028862810108727585, -0.0010346915374488557, 0.3946680705464567, -0.26341324647080366, 0.09509565756560898, 0.04415926185428614] bias =  -0.1354242924939684\n",
      "bias change =  -4.060000000116748e-05\n",
      "....................................................................................................\n",
      "cycle = 450000, errors = 29.0\n",
      "weights change =  2.9759999901804446e-05 -0.003692765000580134\n",
      "weights =  [-0.03351765798716628, 0.33376551319726855, 0.3324944547834552, -0.020724043689995243, 0.1431026843887999, 0.0028304810108721852, -0.00101129153744809, 0.39463200258530795, -0.2632491804693055, 0.09472677856528151, 0.04412997185410749] bias =  -0.1354556924939693\n",
      "bias change =  -3.140000000090293e-05\n",
      "....................................................................................................\n",
      "cycle = 460000, errors = 30.0\n",
      "weights change =  9.642999990169127e-05 -0.003694896000579928\n",
      "weights =  [-0.03342122798726459, 0.3300706171966886, 0.3316557387843849, -0.01990478369004039, 0.14209603868894102, 0.0027536810108716565, -0.0009714915374472105, 0.3945936469871664, -0.2630988474678074, 0.09435214856495427, 0.044085331853929426] bias =  -0.13548939249397027\n",
      "bias change =  -3.3700000000969066e-05\n",
      "....................................................................................................\n",
      "cycle = 470000, errors = 28.0\n",
      "weights change =  0.00012922999990156586 -0.0034303980005568335\n",
      "weights =  [-0.03329199798736302, 0.3266402191961318, 0.33069735878537737, -0.01908529369008152, 0.1410956933890501, 0.0026958810108714095, -0.0009456915374452393, 0.39458851280112406, -0.2627736554663971, 0.09390945856462285, 0.04396762185373935] bias =  -0.1354902924939703\n",
      "bias change =  -9.000000000258801e-07\n",
      "....................................................................................................\n",
      "cycle = 480000, errors = 30.0\n",
      "weights change =  0.00013177999989362477 -0.0029825560006632723\n",
      "weights =  [-0.0331602179874694, 0.3236576631954685, 0.32954551278647676, -0.01848150369012381, 0.14011516148907802, 0.002635081010873362, -0.0009212915374430322, 0.39468150583822637, -0.26206752346495676, 0.09335122356430525, 0.043760801853530894] bias =  -0.1353931924939675\n",
      "bias change =  9.710000000279218e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 490000, errors = 30.0\n",
      "weights change =  0.00013998999989255773 -0.002981339000683203\n",
      "weights =  [-0.03302022798757684, 0.3206763241947853, 0.3283948437875776, -0.017910273690167105, 0.13913602958910154, 0.0025827810108755653, -0.0008962915374408112, 0.39478022353932746, -0.26135084446349216, 0.09279140556399054, 0.043556261853322745] bias =  -0.13529029249396454\n",
      "bias change =  0.00010290000000295896\n",
      "....................................................................................................\n",
      "cycle = 500000, errors = 29.0\n",
      "weights change =  0.00010741999989331147 -0.0030011425006825077\n",
      "weights =  [-0.03291280798768353, 0.3176751816941028, 0.32724735178867154, -0.017468223690211452, 0.1381540662891219, 0.0025314810108778454, -0.0008735915374385486, 0.3948785391644604, -0.2606423644620294, 0.09221464856368135, 0.043395771853114475] bias =  -0.1351874924939616\n",
      "bias change =  0.00010280000000295608\n",
      "....................................................................................................\n",
      "cycle = 510000, errors = 31.0\n",
      "weights change =  0.00010407999989350825 -0.003006747000682264\n",
      "weights =  [-0.03280872798779002, 0.31466843469342054, 0.32610092278976416, -0.017062233690256043, 0.13717137868914123, 0.0024825810108801503, -0.0008539915374362744, 0.39497637704160243, -0.25993793046056707, 0.09163273256337362, 0.04324333185290623] bias =  -0.13508509249395864\n",
      "bias change =  0.00010240000000294458\n",
      "....................................................................................................\n",
      "cycle = 520000, errors = 30.0\n",
      "weights change =  0.00010557999989350281 -0.0030064685006823133\n",
      "weights =  [-0.032703147987896516, 0.3116619661927382, 0.3249545507908567, -0.016654323690300628, 0.1361887323891606, 0.0024346810108824544, -0.0008364915374340007, 0.3950744172687441, -0.25923272645910467, 0.09105117156306584, 0.04309274185269798] bias =  -0.1349824924939557\n",
      "bias change =  0.00010260000000295033\n",
      "....................................................................................................\n",
      "cycle = 530000, errors = 29.0\n",
      "weights change =  0.00010583999989350473 -0.0030066755006822876\n",
      "weights =  [-0.03259730798800301, 0.30865529069205594, 0.3238081907919494, -0.016248103690345215, 0.1352060607891799, 0.0023865810108847597, -0.0008125915374317265, 0.39517235501088616, -0.25852801445764234, 0.09046931156275811, 0.04294163185248974] bias =  -0.13487999249395274\n",
      "bias change =  0.00010250000000294746\n",
      "....................................................................................................\n",
      "cycle = 540000, errors = 30.0\n",
      "weights change =  0.0001051899998935138 -0.0030069010006822383\n",
      "weights =  [-0.0324921179881095, 0.3056483896913737, 0.32266184179304214, -0.015842413690389797, 0.13422338008919915, 0.0023431810108870657, -0.0007929915374294523, 0.39527009373802824, -0.25782409545618, 0.08988723256245038, 0.042787941852281505] bias =  -0.1347776924939498\n",
      "bias change =  0.0001023000000029417\n",
      "....................................................................................................\n",
      "cycle = 550000, errors = 30.0\n",
      "weights change =  0.00010959999989296199 -0.0029999065006792724\n",
      "weights =  [-0.032382517988216536, 0.30264848319069443, 0.3215040437941542, -0.015579188690409326, 0.13324259218921736, 0.0023006810108894184, -0.0007750915374271978, 0.3953713518681536, -0.2571096484547256, 0.08930745156213925, 0.04265380185207486] bias =  -0.13467179249394676\n",
      "bias change =  0.00010590000000304522\n",
      "....................................................................................................\n",
      "cycle = 560000, errors = 30.0\n",
      "weights change =  5.9479999892274316e-05 -0.0029864760006760305\n",
      "weights =  [-0.03232303798832426, 0.2996620071900184, 0.3203294687952859, -0.015460283690400332, 0.13226415138923667, 0.0022639810108917775, -0.0007572915374249788, 0.3954797282222482, -0.2563662134532808, 0.08873828356182317, 0.04256141185186964] bias =  -0.1345586924939435\n",
      "bias change =  0.00011310000000325227\n",
      "....................................................................................................\n",
      "cycle = 570000, errors = 30.0\n",
      "weights change =  6.293999989227805e-05 -0.002986472000676088\n",
      "weights =  [-0.032260097988431984, 0.2966755351893423, 0.3191551287964175, -0.015340633690391334, 0.13128573448925596, 0.002229181010894138, -0.0007442915374227595, 0.395588304305343, -0.25562225745183587, 0.08816920456150712, 0.04247159185166442] bias =  -0.13444539249394025\n",
      "bias change =  0.00011330000000325802\n",
      "....................................................................................................\n",
      "cycle = 580000, errors = 28.0\n",
      "weights change =  5.855999989227978e-05 -0.0029863960006760726\n",
      "weights =  [-0.032201537988539704, 0.29368913918866624, 0.3179806067975489, -0.015219763690382342, 0.13030728748927534, 0.0021933810108964954, -0.0007290915374205406, 0.3956967816554374, -0.25487831945039097, 0.08760026656119105, 0.042380091851459176] bias =  -0.134332192493937\n",
      "bias change =  0.00011320000000325514\n",
      "....................................................................................................\n",
      "cycle = 590000, errors = 30.0\n",
      "weights change =  6.247999989227732e-05 -0.0029863370006761314\n",
      "weights =  [-0.032139057988647426, 0.2907028021879901, 0.31680629679868033, -0.015098358690373346, 0.1293288659892947, 0.0021583810108988543, -0.0007110915374183215, 0.3958054584355321, -0.254133872448946, 0.087031391560875, 0.04229140185125394] bias =  -0.13421879249393373\n",
      "bias change =  0.00011340000000326089\n",
      "....................................................................................................\n",
      "cycle = 600000, errors = 29.0\n",
      "weights change =  1.7239999888660207e-05 -0.002793700000576216\n",
      "weights =  [-0.032121817988758766, 0.2879091021874139, 0.31557543079992306, -0.01497179869036282, 0.1283815284893172, 0.002132581010901523, -0.0007025915374161597, 0.3959629879346326, -0.2531843554475839, 0.08642858156055772, 0.042179761851042025] bias =  -0.13405619249392906\n",
      "bias change =  0.00016260000000467567\n",
      "....................................................................................................\n",
      "cycle = 610000, errors = 28.0\n",
      "weights change =  -6.562000011939989e-05 -0.0023679580003537204\n",
      "weights =  [-0.032187437988878166, 0.28554114418706017, 0.31421949980141634, -0.014843763690348843, 0.12750329038934546, 0.002136181010904899, -0.0007108915374141227, 0.3962258661977488, -0.25179305544640634, 0.08574608056023762, 0.04198310185081554] bias =  -0.13378749249392133\n",
      "bias change =  0.00026870000000772665\n",
      "....................................................................................................\n",
      "cycle = 620000, errors = 29.0\n",
      "weights change =  -6.652000011941883e-05 -0.0023670370003535113\n",
      "weights =  [-0.032253957988997585, 0.28317410718670666, 0.31286350080290953, -0.014710543690334867, 0.12662513358937388, 0.0021337810109082725, -0.000709991537412086, 0.396488947616865, -0.25040061444522893, 0.08506381055991755, 0.04178711185058898] bias =  -0.1335185924939136\n",
      "bias change =  0.0002689000000077324\n",
      "....................................................................................................\n",
      "cycle = 630000, errors = 29.0\n",
      "weights change =  -6.768000011941194e-05 -0.0023674090003536485\n",
      "weights =  [-0.032321637989117, 0.280806698186353, 0.31150757680440255, -0.014576338690320894, 0.1257469135894023, 0.002131581010911645, -0.0007086915374100492, 0.39675173223398114, -0.24900921844487328, 0.08438147755959746, 0.04158844185036243] bias =  -0.13324999249390587\n",
      "bias change =  0.00026860000000772377\n",
      "....................................................................................................\n",
      "cycle = 640000, errors = 28.0\n",
      "weights change =  -6.657000011941333e-05 -0.0023671730003535507\n",
      "weights =  [-0.03238820798923641, 0.27843952518599946, 0.31015165580589565, -0.014442288690306917, 0.1248687415894261, 0.002130681010915018, -0.0007106915374080125, 0.3970147153620973, -0.24761714744484986, 0.08369918455927738, 0.04139140185013587] bias =  -0.13298119249389814\n",
      "bias change =  0.0002688000000077295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 650000, errors = 29.0\n",
      "weights change =  -6.532000011941208e-05 -0.0023672060003536166\n",
      "weights =  [-0.03245352798935582, 0.27607231918564584, 0.3087958258073887, -0.01430802869029294, 0.12399056658942348, 0.0021304810109183917, -0.0007113915374059756, 0.39727779801421353, -0.24622478444482646, 0.08301698155895731, 0.04119588184990932] bias =  -0.1327122924938904\n",
      "bias change =  0.0002689000000077324\n",
      "....................................................................................................\n",
      "cycle = 660000, errors = 28.0\n",
      "weights change =  -6.759000011941768e-05 -0.002366954000353416\n",
      "weights =  [-0.03252111798947524, 0.2737053651852924, 0.30743978180888193, -0.014174068690278962, 0.12311242488942081, 0.002129581010921765, -0.000712491537403939, 0.39754078095632966, -0.244832626444803, 0.08233462555863723, 0.04099803184968275] bias =  -0.13244349249388268\n",
      "bias change =  0.0002688000000077295\n",
      "....................................................................................................\n",
      "cycle = 670000, errors = 29.0\n",
      "weights change =  -6.566000011941353e-05 -0.0023671330003535718\n",
      "weights =  [-0.032586777989594654, 0.27133823218493885, 0.306083910810375, -0.014039838690264985, 0.12223425998941818, 0.0021293810109251385, -0.0007128915374019023, 0.39780386354644587, -0.24344023444477958, 0.08165240155831716, 0.040802241849456196] bias =  -0.13217459249387495\n",
      "bias change =  0.0002689000000077324\n",
      "....................................................................................................\n",
      "cycle = 680000, errors = 29.0\n",
      "weights change =  -6.666000011940759e-05 -0.002367628000353783\n",
      "weights =  [-0.03265343798971406, 0.26897060418458507, 0.3047281098118679, -0.013905543690251012, 0.1213560096894156, 0.002127181010928511, -0.0007124915373998654, 0.39806664834956207, -0.24204892544475623, 0.08097013155799708, 0.040604381849229654] bias =  -0.13190599249386722\n",
      "bias change =  0.00026860000000772377\n",
      "....................................................................................................\n",
      "cycle = 690000, errors = 28.0\n",
      "weights change =  -6.572000011941664e-05 -0.002366828000353427\n",
      "weights =  [-0.03271915798983348, 0.26660377618423164, 0.30337218881336103, -0.013770748690237032, 0.12047789398941293, 0.0021267810109318846, -0.0007170915373978287, 0.39832983082467827, -0.24065611244473278, 0.08028790155767701, 0.04040874184900308] bias =  -0.1316369924938595\n",
      "bias change =  0.0002690000000077353\n",
      "....................................................................................................\n",
      "cycle = 700000, errors = 29.0\n",
      "weights change =  -6.68100001194119e-05 -0.00236738700035366\n",
      "weights =  [-0.03278596798995289, 0.264236389183878, 0.30201629581485406, -0.013636828690223058, 0.11959968198941032, 0.0021256810109352574, -0.0007143915373957919, 0.39859271445479444, -0.2392644144447094, 0.07960561555735693, 0.04021130184877653] bias =  -0.13136829249385176\n",
      "bias change =  0.00026870000000772665\n",
      "....................................................................................................\n",
      "cycle = 710000, errors = 28.0\n",
      "weights change =  -2.708000011996531e-05 -0.002346785000342466\n",
      "weights =  [-0.032813047990072855, 0.2618896041835355, 0.3006561498163609, -0.013521143690209021, 0.11872467198940681, 0.0021243810109386756, -0.0007174915373937648, 0.39886138589391223, -0.2378575304446819, 0.07892036055703615, 0.03998515184854989] bias =  -0.13109379249384387\n",
      "bias change =  0.00027450000000789343\n",
      "....................................................................................................\n",
      "cycle = 720000, errors = 28.0\n",
      "weights change =  0.00013136999987749948 -0.002248609000291002\n",
      "weights =  [-0.032681677990195356, 0.2596409951832445, 0.2992769188179275, -0.0134302936901947, 0.11786448058939795, 0.0020981810109422694, -0.0007078915373917833, 0.39915605054403636, -0.23637780944463677, 0.07822329155671237, 0.03962061184832209] bias =  -0.13079329249383523\n",
      "bias change =  0.0003005000000086411\n",
      "....................................................................................................\n",
      "cycle = 730000, errors = 28.0\n",
      "weights change =  0.00013544999987690626 -0.002221569000276924\n",
      "weights =  [-0.03254622799031845, 0.2574194261829676, 0.29788983381951006, -0.013356433690180263, 0.11700841148938691, 0.0020712810109459055, -0.0006922915373898135, 0.39945866582116013, -0.23486961244458698, 0.07752324355638801, 0.03924555184809369] bias =  -0.13048479249382636\n",
      "bias change =  0.0003085000000088711\n",
      "....................................................................................................\n",
      "cycle = 740000, errors = 28.0\n",
      "weights change =  0.00013225999987701714 -0.0022248000002789703\n",
      "weights =  [-0.03241396799044143, 0.2551946261826886, 0.29650431282108924, -0.013265028690165832, 0.11615181278937592, 0.00204958101094953, -0.0006859915373878422, 0.39976019979428373, -0.23336424844453815, 0.0768241165560638, 0.038872791847865205] bias =  -0.13017739249381752\n",
      "bias change =  0.0003074000000088395\n",
      "....................................................................................................\n",
      "cycle = 750000, errors = 31.0\n",
      "weights change =  0.0001331099998770069 -0.002224603000278935\n",
      "weights =  [-0.032280857990564425, 0.2529700231824097, 0.29511870282266855, -0.013175273690151403, 0.11529523548936493, 0.002023681010953155, -0.0006775915373858708, 0.4000619307034074, -0.23185822444448928, 0.0761250515557396, 0.03850225184763673] bias =  -0.12986979249380867\n",
      "bias change =  0.00030760000000884524\n",
      "....................................................................................................\n",
      "cycle = 760000, errors = 28.0\n",
      "weights change =  0.00013030999987700964 -0.0022245410002789123\n",
      "weights =  [-0.032150547990687416, 0.2507454821821308, 0.29373303282424773, -0.013083018690136974, 0.11443864798935388, 0.001997081010956778, -0.0006678915373838995, 0.40036346466653094, -0.23035258144444046, 0.07542596155541541, 0.038129471847408225] bias =  -0.12956239249379983\n",
      "bias change =  0.0003074000000088395\n",
      "....................................................................................................\n",
      "cycle = 770000, errors = 29.0\n",
      "weights change =  0.0001313999998770049 -0.0022246569998340127\n",
      "weights =  [-0.03201914799081041, 0.24852082518229676, 0.292347375825827, -0.012992238690122547, 0.11358204108934288, 0.0019690810109604016, -0.0006551915373819282, 0.40066499783865456, -0.2288471364443916, 0.0747268585550912, 0.03775680184717974] bias =  -0.129254992493791\n",
      "bias change =  0.0003074000000088395\n",
      "....................................................................................................\n",
      "cycle = 780000, errors = 29.0\n",
      "weights change =  0.0001335799998770093 -0.002224428999610034\n",
      "weights =  [-0.0318855679909334, 0.24629639618268673, 0.2909617748274065, -0.012902068690108114, 0.11272551428933188, 0.0019498810109627369, -0.0006491915373799571, 0.4009667299437782, -0.22734121844434269, 0.07402767755476698, 0.037384611846951264] bias =  -0.12894739249378215\n",
      "bias change =  0.00030760000000884524\n",
      "....................................................................................................\n",
      "cycle = 790000, errors = 28.0\n",
      "weights change =  0.00013090999987700608 -0.002224374999609896\n",
      "weights =  [-0.031754657991056395, 0.24407202118307683, 0.28957607982898576, -0.012810178690093684, 0.11186895608932082, 0.0019231810109622868, -0.0006408915373779858, 0.40126836308790176, -0.22583526644429383, 0.07332858755444278, 0.03701237184672276] bias =  -0.1286398924937733\n",
      "bias change =  0.00030750000000884237\n",
      "....................................................................................................\n",
      "cycle = 800000, errors = 28.0\n",
      "weights change =  0.00013774999988007408 -0.002210584999615184\n",
      "weights =  [-0.03161690799117632, 0.24186143618346165, 0.28816711783050847, -0.012806923690078173, 0.11097949388930563, 0.00190328101096172, -0.0006295915373760064, 0.4015504634200734, -0.2243934174442445, 0.07257587055412573, 0.03666499184649501] bias =  -0.12835189249376502\n",
      "bias change =  0.00028800000000828163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 810000, errors = 29.0\n",
      "weights change =  8.719999988689858e-05 -0.002192377999619133\n",
      "weights =  [-0.03152970799128942, 0.23966905818384251, 0.28672093483192684, -0.012830553690061431, 0.11003443608927459, 0.0018836810109610388, -0.0006215915373740379, 0.4017947461923178, -0.22305435544420588, 0.07174871955381593, 0.03640312184626718] bias =  -0.12810179249375783\n",
      "bias change =  0.0002501000000071918\n",
      "....................................................................................................\n",
      "cycle = 820000, errors = 27.0\n",
      "weights change =  0.00016208999989984763 -0.0021785289996253676\n",
      "weights =  [-0.031367617991389575, 0.23749052918421715, 0.2852349378332541, -0.012831313690046172, 0.10902951848919779, 0.0018531810109605942, -0.0006162915373722123, 0.4019774122486311, -0.22187945244421098, 0.0708787785534877, 0.036153431846040446] bias =  -0.12791389249375243\n",
      "bias change =  0.0001879000000054032\n",
      "....................................................................................................\n",
      "cycle = 830000, errors = 27.0\n",
      "weights change =  0.00016360999992103692 -0.002176548999626493\n",
      "weights =  [-0.031204007991468538, 0.23531398018459065, 0.28374229583456745, -0.01284235369003101, 0.10801564838911543, 0.0018220810109601698, -0.0006052915373704022, 0.40215202723195487, -0.22072558944422108, 0.07000063555315786, 0.03591506184581388] bias =  -0.12773409249374726\n",
      "bias change =  0.00017980000000517027\n",
      "....................................................................................................\n",
      "cycle = 840000, errors = 26.0\n",
      "weights change =  0.00016663999996518325 -0.0021766149996265416\n",
      "weights =  [-0.031037367991503355, 0.2331373651849641, 0.2822498658358809, -0.012853123690015851, 0.1070018134890331, 0.0017943810109597455, -0.0005985915373685922, 0.4023266446582787, -0.21957210944423117, 0.06912250855282798, 0.03567541184558734] bias =  -0.1275542924937421\n",
      "bias change =  0.00017980000000517027\n",
      "....................................................................................................\n",
      "cycle = 850000, errors = 27.0\n",
      "weights change =  0.0001652999999651808 -0.0021765389996264983\n",
      "weights =  [-0.030872067991538174, 0.23096082618533761, 0.2807573478371943, -0.01286377369000069, 0.10598798098895076, 0.0017653810109593212, -0.0005866915373667821, 0.4025013599926025, -0.21841803344424127, 0.06824446755249812, 0.03543774184536078] bias =  -0.12737439249373692\n",
      "bias change =  0.00017990000000517314\n",
      "....................................................................................................\n",
      "cycle = 860000, errors = 28.0\n",
      "weights change =  0.00016206999996517396 -0.00217663099962645\n",
      "weights =  [-0.030709997991573, 0.22878419518571116, 0.2792647748385077, -0.012873973689985526, 0.10497424778886842, 0.0017371810109588967, -0.0005779915373649718, 0.402676172574926, -0.21726322644425136, 0.0673665605521683, 0.03520157184513419] bias =  -0.12719439249373174\n",
      "bias change =  0.00018000000000517602\n",
      "....................................................................................................\n",
      "cycle = 870000, errors = 27.0\n",
      "weights change =  0.00016324999996517736 -0.0021766779996265084\n",
      "weights =  [-0.030546747991607823, 0.22660751718608466, 0.27777219383982116, -0.012884963689970365, 0.10396043608878609, 0.0017057810109584724, -0.0005763915373631617, 0.4028506889992497, -0.21610981144426145, 0.06648838255183845, 0.03496101184490763] bias =  -0.12701469249372657\n",
      "bias change =  0.0001797000000051674\n",
      "....................................................................................................\n",
      "cycle = 880000, errors = 27.0\n",
      "weights change =  0.00016496999996518102 -0.0021765669996265113\n",
      "weights =  [-0.03038177799164264, 0.22443095018645814, 0.2762796508411345, -0.012895703689955202, 0.10294657528870374, 0.001678881010958048, -0.0005642915373613516, 0.4030254037135735, -0.21495567244427155, 0.0656102995515086, 0.03472386184468107] bias =  -0.1268347924937214\n",
      "bias change =  0.00017990000000517314\n",
      "....................................................................................................\n",
      "cycle = 890000, errors = 27.0\n",
      "weights change =  0.0001652499999651759 -0.0021766109996264604\n",
      "weights =  [-0.030216527991677466, 0.22225433918683168, 0.27478731284244823, -0.012905463689940045, 0.10193296318862147, 0.001649181010957624, -0.0005554915373595414, 0.403200219898897, -0.2138013614442816, 0.06473252455117873, 0.034484991844454506] bias =  -0.12665479249371622\n",
      "bias change =  0.00018000000000517602\n",
      "....................................................................................................\n",
      "cycle = 900000, errors = 28.0\n",
      "weights change =  0.00016852999996529866 -0.002178190999625629\n",
      "weights =  [-0.030047997991712167, 0.22007614818720606, 0.27329473784375946, -0.012912323689924928, 0.1009195569885392, 0.001620981010957206, -0.0005451915373577282, 0.40337403604122096, -0.21265062444429167, 0.06385618155084898, 0.034244701844228016] bias =  -0.12647579249371108\n",
      "bias change =  0.00017900000000514726\n",
      "....................................................................................................\n",
      "cycle = 910000, errors = 28.0\n",
      "weights change =  0.00014879999996901538 -0.0022315289995960552\n",
      "weights =  [-0.029899197991743152, 0.21784461918761, 0.2717916478449905, -0.012807833689911017, 0.09991706288845728, 0.0015929810109569804, -0.0005332915373558069, 0.40351885208354926, -0.21158909444430157, 0.06303261255052459, 0.03400609184400272] bias =  -0.12632569249370676\n",
      "bias change =  0.00015010000000431623\n",
      "....................................................................................................\n",
      "cycle = 920000, errors = 27.0\n",
      "weights change =  0.00014053999997006017 -0.0022433099995898542\n",
      "weights =  [-0.02975865799177309, 0.21560130918802015, 0.2702810188461922, -0.012701463689897306, 0.09891125298837357, 0.0015613810109567953, -0.0005210915373538613, 0.4036528293318864, -0.21055946744431267, 0.062214097550341026, 0.03378688184377789] bias =  -0.12618639249370275\n",
      "bias change =  0.00013930000000400566\n",
      "....................................................................................................\n",
      "cycle = 930000, errors = 27.0\n",
      "weights change =  0.00014267999997033196 -0.0022461669995884337\n",
      "weights =  [-0.02961597799180276, 0.2133551421884317, 0.26876851184738637, -0.012595793689883644, 0.09790433738828937, 0.0015309810109566202, -0.0005096915373519101, 0.4037839000732263, -0.2095389494443241, 0.061396424550416065, 0.03357117184355323] bias =  -0.12604999249369883\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 940000, errors = 28.0\n",
      "weights change =  0.00014164999997034328 -0.0022464979995883427\n",
      "weights =  [-0.029474327991832416, 0.21110864418884337, 0.2672559988485803, -0.012489533689869985, 0.09689752458820519, 0.0015058810109564457, -0.0004980915373499585, 0.40391486986256603, -0.20851869444433552, 0.06057896755049113, 0.033355191843328566] bias =  -0.1259136924936949\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 950000, errors = 28.0\n",
      "weights change =  0.00014392999997033668 -0.002246262999588383\n",
      "weights =  [-0.02933039799186208, 0.208862381189255, 0.2657436328497746, -0.012383213689856329, 0.09589074258812104, 0.0014748810109562712, -0.0004881915373479782, 0.40404594205790584, -0.20749838444434693, 0.05976151255056616, 0.033138211843103914] bias =  -0.125777292493691\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 960000, errors = 27.0\n",
      "weights change =  0.00014234999997033218 -0.0022461949995884467\n",
      "weights =  [-0.029188047991891748, 0.20661618618966654, 0.2642311008509687, -0.012277633689842665, 0.09488379868803683, 0.001446581010956096, -0.0004765915373464197, 0.40417701217924573, -0.20647780344435837, 0.058943797550641205, 0.03292302184287925] bias =  -0.12564089249368707\n",
      "bias change =  0.00013640000000392227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 970000, errors = 28.0\n",
      "weights change =  0.00014332999997033677 -0.002246333999588429\n",
      "weights =  [-0.02904471799192141, 0.2043698521900781, 0.2627186718521629, -0.012171763689829007, 0.09387695488795267, 0.0014194810109559213, -0.00046509153734664894, 0.40430798431558557, -0.20545782944436977, 0.05812618155071624, 0.0327053518426546] bias =  -0.12550459249368315\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 980000, errors = 28.0\n",
      "weights change =  0.00014070999997034192 -0.002246422999588299\n",
      "weights =  [-0.02890400799195107, 0.2021234291904898, 0.2612060798533568, -0.012065543689815349, 0.09287013598786847, 0.0013890810109557469, -0.0004544915373471657, 0.4044389536129253, -0.2044374424443812, 0.057308754550791305, 0.03248970184242993] bias =  -0.12536829249367923\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 990000, errors = 28.0\n",
      "weights change =  0.0001439499999703331 -0.0022462139995884645\n",
      "weights =  [-0.028760057991980736, 0.19987721519090135, 0.2596936768545511, -0.011959743689801688, 0.0918632547877843, 0.0013618810109555719, -0.0004422915373476828, 0.4045700254662652, -0.2034171194443926, 0.05649109355086634, 0.032273141842205276] bias =  -0.1252318924936753\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 1000000, errors = 28.0\n",
      "weights change =  0.00014305999997033317 -0.0022461699995884044\n",
      "weights =  [-0.028616997992010403, 0.19763104519131294, 0.2581812088557453, -0.01185384368978803, 0.09085639188770012, 0.001329581010955397, -0.0004309915373482, 0.40470109682860506, -0.20239667244440404, 0.05567351355094137, 0.03205687184198062] bias =  -0.12509549249367138\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 1010000, errors = 26.0\n",
      "weights change =  0.0001410299999703435 -0.0022464689995882747\n",
      "weights =  [-0.02847596799204006, 0.19538457619172467, 0.2566686748569392, -0.011747333689774373, 0.08984962718761594, 0.0012979810109552228, -0.00042429153734871715, 0.40483206667694477, -0.20137634044441546, 0.05485617155101643, 0.03184077184175595] bias =  -0.12495919249366746\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1020000, errors = 27.0\n",
      "weights change =  0.00014182999997033874 -0.0022463769995883787\n",
      "weights =  [-0.02833413799206972, 0.1931381991921363, 0.25515614485813326, -0.011641403689760714, 0.08884276948753175, 0.001270181010955048, -0.0004131915373492343, 0.40496303708328457, -0.20035612444442688, 0.05403860355109148, 0.031624391841531284] bias =  -0.12482289249366355\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1030000, errors = 29.0\n",
      "weights change =  0.00014310999997033808 -0.0022463499995884206\n",
      "weights =  [-0.028191027992099382, 0.19089184919254787, 0.25364368585932745, -0.011535543689747055, 0.08783592028744759, 0.0012446810109548734, -0.0003975915373497515, 0.4050940086706244, -0.19933611144443827, 0.053221004551166524, 0.031407091841306634] bias =  -0.12468659249365963\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1040000, errors = 28.0\n",
      "weights change =  0.0001430999999703364 -0.002246216999588352\n",
      "weights =  [-0.028047927992129046, 0.18864563219295952, 0.25213125886052157, -0.011429093689733397, 0.0868291113873634, 0.0012130810109546987, -0.0003872915373502686, 0.4052251788539642, -0.19831521844444971, 0.052403603551241566, 0.031192471841150926] bias =  -0.1245500924936557\n",
      "bias change =  0.00013650000000392515\n",
      "....................................................................................................\n",
      "cycle = 1050000, errors = 28.0\n",
      "weights change =  0.00014357999997034396 -0.0022464889995883475\n",
      "weights =  [-0.027904347992158702, 0.18639914319337117, 0.25061889986171576, -0.011322523689719742, 0.08582238958727928, 0.0011869810109545245, -0.00037529153735078576, 0.4053561509953039, -0.1972952844444611, 0.05158624255131661, 0.03097460184117864] bias =  -0.12441379249365178\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1060000, errors = 28.0\n",
      "weights change =  0.00014143999997033932 -0.002246348999588338\n",
      "weights =  [-0.027762907992188363, 0.18415279419378283, 0.2491063348623565, -0.011216503689706085, 0.08481555248719509, 0.00115638101095435, -0.00036269153735130294, 0.4054871211916437, -0.1962750184444725, 0.05076874455139166, 0.03075829184120635] bias =  -0.12427749249364786\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1070000, errors = 28.0\n",
      "weights change =  0.00014326999997033713 -0.002246318999588409\n",
      "weights =  [-0.027619637992218025, 0.18190647519419442, 0.24759391886261434, -0.011110363689692425, 0.08380871388711092, 0.0011295810109541752, -0.00035239153735182007, 0.4056181921469835, -0.19525458244448393, 0.049951205551466704, 0.03054235184123406] bias =  -0.12414109249364394\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 1080000, errors = 27.0\n",
      "weights change =  0.00014267999997033196 -0.0022461669995884337\n",
      "weights =  [-0.027476957992247694, 0.179660308194606, 0.2460814118628722, -0.011004693689678763, 0.08280179828702672, 0.0010991810109540001, -0.00034099153735233723, 0.4057492628883234, -0.19423406444449537, 0.04913353255154174, 0.03032664184126177] bias =  -0.12400469249364002\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 1090000, errors = 29.0\n",
      "weights change =  0.00014258999997034116 -0.00224638299958832\n",
      "weights =  [-0.027334367992277352, 0.17741392519501767, 0.24456895986313001, -0.01089830368966511, 0.08179504598694257, 0.001067581010953826, -0.0003300915373528544, 0.40588023453666316, -0.19321399044450677, 0.04831615055161678, 0.030109141841289485] bias =  -0.1238683924936361\n",
      "bias change =  0.0001363000000039194\n",
      "....................................................................................................\n",
      "cycle = 1100000, errors = 27.0\n",
      "weights change =  0.00014196999997033097 -0.002246191999588476\n",
      "weights =  [-0.02719239799230702, 0.1751677331954292, 0.24305638886338785, -0.010792953689651443, 0.08078804938685834, 0.0010411810109536505, -0.00031839153735337155, 0.4060113040370031, -0.19219333844451822, 0.04749834255169184, 0.029894511841317188] bias =  -0.12373199249363218\n",
      "bias change =  0.00013640000000392227\n",
      "....................................................................................................\n",
      "cycle = 1110000, errors = 29.0\n",
      "weights change =  0.00015345999997097917 -0.002241451999583144\n",
      "weights =  [-0.027038937992336042, 0.17292628119584605, 0.24154017086364643, -0.010691083689638298, 0.07978424898677429, 0.0010027810109534921, -0.0003140915373538834, 0.4061413584243395, -0.19117417744452966, 0.04668680755176594, 0.029673501841345012] bias =  -0.12359659249362828\n",
      "bias change =  0.00013540000000389352\n",
      "....................................................................................................\n",
      "cycle = 1120000, errors = 29.0\n",
      "weights change =  0.00018622999998455653 -0.002149087999471555\n",
      "weights =  [-0.026852707992351486, 0.1707771931963745, 0.23993148186391478, -0.010696003689635537, 0.07883838418668976, 0.0009678810109536665, -0.000308191537354287, 0.4062456717136036, -0.19017115344454266, 0.04599597155182283, 0.0294630218413745] bias =  -0.12348639249362511\n",
      "bias change =  0.00011020000000316887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 1130000, errors = 30.0\n",
      "weights change =  0.0001395399999864766 -0.002159189999451916\n",
      "weights =  [-0.02671316799236501, 0.16861800319692258, 0.238317045864178, -0.01064093368963402, 0.07790886348660743, 0.0009605810109529904, -0.00030469153735468137, 0.4063459801308494, -0.18916978044455424, 0.04534172155187937, 0.02926346184140404] bias =  -0.12338009249362206\n",
      "bias change =  0.00010630000000305673\n",
      "....................................................................................................\n",
      "cycle = 1140000, errors = 30.0\n",
      "weights change =  0.00013701999998648115 -0.0021591339994516956\n",
      "weights =  [-0.026576147992378528, 0.16645886919747088, 0.2367024738644411, -0.010584843689632506, 0.07697943088652505, 0.0009433810109521973, -0.0003034915373550757, 0.40644648437609504, -0.18816713844456587, 0.044687917551935935, 0.02906845184143357] bias =  -0.123273592493619\n",
      "bias change =  0.00010650000000306248\n",
      "....................................................................................................\n",
      "cycle = 1150000, errors = 29.0\n",
      "weights change =  0.00013770999998647532 -0.002159026999451724\n",
      "weights =  [-0.026438437992392053, 0.16429984219801916, 0.2350879298647042, -0.01052866368963099, 0.07604998168644267, 0.0009256810109514043, -0.0002912915373554701, 0.40654708847934073, -0.18716420744457749, 0.0440341455519925, 0.028874291841463104] bias =  -0.12316699249361593\n",
      "bias change =  0.00010660000000306535\n",
      "....................................................................................................\n",
      "cycle = 1160000, errors = 30.0\n",
      "weights change =  0.0001366099999864749 -0.0021590949994519104\n",
      "weights =  [-0.026301827992405578, 0.16214074719856725, 0.2334732318649674, -0.01047451368962947, 0.07512031348636027, 0.0009139810109506112, -0.00029839153735586446, 0.4066472950915866, -0.18616277544458912, 0.04337962455204905, 0.028675521841492635] bias =  -0.12306079249361287\n",
      "bias change =  0.00010620000000305385\n",
      "....................................................................................................\n",
      "cycle = 1170000, errors = 28.0\n",
      "weights change =  0.00013433999998647625 -0.0021591759994516735\n",
      "weights =  [-0.0261674879924191, 0.15998157119911557, 0.23185842986523048, -0.010418943689627955, 0.07419081828627787, 0.0008920810109498184, -0.000284491537356259, 0.40674759899683227, -0.1851606824446007, 0.04272573355210563, 0.02847897184152217] bias =  -0.12295449249360982\n",
      "bias change =  0.00010630000000305673\n",
      "....................................................................................................\n",
      "cycle = 1180000, errors = 30.0\n",
      "weights change =  0.0001388199999864878 -0.00215924599945172\n",
      "weights =  [-0.026028667992432614, 0.15782232519966385, 0.2302440178654936, -0.010362613689626442, 0.07326145038619553, 0.0008811810109490252, -0.00029019153735665323, 0.4068481044960779, -0.18415826544461233, 0.042071955552162185, 0.0282830718415517] bias =  -0.12284799249360676\n",
      "bias change =  0.00010650000000306248\n",
      "....................................................................................................\n",
      "cycle = 1190000, errors = 30.0\n",
      "weights change =  0.00013666999998647456 -0.002159058999451874\n",
      "weights =  [-0.02589199799244614, 0.15566326620021198, 0.22862932186575677, -0.010308103689624922, 0.07233180848611312, 0.0008689810109482321, -0.0002894915373570476, 0.4069484100683237, -0.18315642144462396, 0.041417583552218744, 0.02808577184158123] bias =  -0.1227416924936037\n",
      "bias change =  0.00010630000000305673\n",
      "....................................................................................................\n",
      "cycle = 1200000, errors = 28.0\n",
      "weights change =  0.0001349699999864673 -0.002158924999451778\n",
      "weights =  [-0.025757027992459672, 0.1535043412007602, 0.2270145258660199, -0.010253163689623403, 0.07140218548603068, 0.0008448810109474392, -0.00028449153735744207, 0.40704881416556954, -0.1821539604446356, 0.04076341355227531, 0.02789023184161076] bias =  -0.12263529249360064\n",
      "bias change =  0.0001064000000030596\n",
      "....................................................................................................\n",
      "cycle = 1210000, errors = 29.0\n",
      "weights change =  0.00013856999998648062 -0.002159186999451723\n",
      "weights =  [-0.02561845799247319, 0.15134515420130848, 0.225400095866283, -0.01019678368962189, 0.07047281528594834, 0.0008291810109466461, -0.0002813915373578364, 0.4071493201428152, -0.1811515864446472, 0.04010966855233186, 0.027693851841640298] bias =  -0.12252879249359758\n",
      "bias change =  0.00010650000000306248\n",
      "....................................................................................................\n",
      "cycle = 1220000, errors = 28.0\n",
      "weights change =  0.00015639999998539808 -0.00201997399945536\n",
      "weights =  [-0.025462057992487793, 0.14932518020185312, 0.22371106786655098, -0.01020270368962007, 0.06953638228585872, 0.0008222810109458596, -0.00028039153735823485, 0.40724597027805953, -0.1801406514446359, 0.03941162455239034, 0.027519261841669522] bias =  -0.12242589249359462\n",
      "bias change =  0.00010290000000295896\n",
      "....................................................................................................\n",
      "cycle = 1230000, errors = 28.0\n",
      "weights change =  0.0002555999999826232 -0.001747279999471607\n",
      "weights =  [-0.02520645799250517, 0.1475779002023815, 0.2218844738668336, -0.01037521368961736, 0.06857839098575454, 0.0007871810109450812, -0.0002779915373586422, 0.40733653784831175, -0.17912093244458252, 0.03860972155245134, 0.027338591841698383] bias =  -0.12232869249359182\n",
      "bias change =  9.720000000279505e-05\n",
      "....................................................................................................\n",
      "cycle = 1240000, errors = 28.0\n",
      "weights change =  0.000255769999982617 -0.0017466929994717217\n",
      "weights =  [-0.024950687992522553, 0.1458312072029098, 0.2200575378671163, -0.010548803689614644, 0.06762025978565031, 0.0007564810109443028, -0.0002773915373590495, 0.40742700497056406, -0.17810153544452906, 0.037807335552512346, 0.027157101841727243] bias =  -0.12223159249358903\n",
      "bias change =  9.710000000279218e-05\n",
      "....................................................................................................\n",
      "cycle = 1250000, errors = 28.0\n",
      "weights change =  0.0002558099999826098 -0.001746368999471698\n",
      "weights =  [-0.024694877992539943, 0.1440848382034381, 0.21823050586739898, -0.010722133689611928, 0.06666214178554607, 0.0007196810109435244, -0.00027459153735945687, 0.40751757145281636, -0.17708171444447557, 0.03700500355257335, 0.026976611841756103] bias =  -0.12213439249358624\n",
      "bias change =  9.720000000279505e-05\n",
      "....................................................................................................\n",
      "cycle = 1260000, errors = 30.0\n",
      "weights change =  0.00022914999998088423 -0.0016738609994746134\n",
      "weights =  [-0.02446572799255906, 0.14241097720396348, 0.21638393986767632, -0.010861123689609118, 0.06571898818544411, 0.0006913810109426794, -0.00027409153735984734, 0.4076252342850382, -0.1759969764444072, 0.0361987005526343, 0.02677192184178311] bias =  -0.12201999249358295\n",
      "bias change =  0.00011440000000328965\n",
      "....................................................................................................\n",
      "cycle = 1270000, errors = 30.0\n",
      "weights change =  0.00016889999997790964 -0.0015644669994762106\n",
      "weights =  [-0.02429682799258115, 0.14084651020448727, 0.21451666786794002, -0.010890473689606339, 0.0648120640853494, 0.0006837810109416992, -0.0002776915373602023, 0.4077685339781946, -0.17478171244431345, 0.035404264552694936, 0.02651680184180644] bias =  -0.12186979249357863\n",
      "bias change =  0.0001502000000043191\n",
      "....................................................................................................\n",
      "cycle = 1280000, errors = 29.0\n",
      "weights change =  0.0001713099999775744 -0.0015545589994761522\n",
      "weights =  [-0.024125517992603575, 0.13929195120501112, 0.2126494958682021, -0.010900283689603598, 0.06391062108525611, 0.0006695810109407025, -0.00027389153736055304, 0.40791623250534265, -0.17355277044421677, 0.03461359855275543, 0.026243201841829388] bias =  -0.12171519249357418\n",
      "bias change =  0.00015460000000444563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 1290000, errors = 29.0\n",
      "weights change =  0.00017221999997759155 -0.0015550319994759587\n",
      "weights =  [-0.023953297992625983, 0.13773691920553516, 0.21078268586846402, -0.01090847368960086, 0.06300924138516278, 0.0006553810109397059, -0.0002646915373609037, 0.40806442655149067, -0.1723217074441203, 0.03382365755281593, 0.025978271841852328] bias =  -0.12156009249356972\n",
      "bias change =  0.00015510000000446\n",
      "....................................................................................................\n",
      "cycle = 1300000, errors = 28.0\n",
      "weights change =  0.00017183999997755564 -0.0015538169994760986\n",
      "weights =  [-0.023781457992648428, 0.13618310220605906, 0.20891552386872597, -0.010916723689598121, 0.0621081432851543, 0.0006368810109387081, -0.0002689915373612542, 0.4082125239946382, -0.17109133844402347, 0.033033324552876414, 0.02570563184187525] bias =  -0.12140509249356526\n",
      "bias change =  0.00015500000000445713\n",
      "....................................................................................................\n",
      "cycle = 1310000, errors = 30.0\n",
      "weights change =  0.00017271999997758164 -0.0015549209994760727\n",
      "weights =  [-0.023608737992670846, 0.134628181206583, 0.207048715868988, -0.010925323689595385, 0.06120687028525591, 0.0006232810109377112, -0.0002694915373616048, 0.4083604228237861, -0.16986180444392684, 0.0322430945529369, 0.025433481841898194] bias =  -0.12125029249356081\n",
      "bias change =  0.00015480000000445138\n",
      "....................................................................................................\n",
      "cycle = 1320000, errors = 29.0\n",
      "weights change =  0.00017020999997758787 -0.001555058999476\n",
      "weights =  [-0.023438527992693258, 0.133073122207107, 0.2051817938692499, -0.010934093689592646, 0.060305527285357485, 0.0006118810109367142, -0.0002687915373619554, 0.40850841770793395, -0.1686314224438303, 0.0314529275529974, 0.025165231841921123] bias =  -0.12109539249355636\n",
      "bias change =  0.00015490000000445425\n",
      "....................................................................................................\n",
      "cycle = 1330000, errors = 29.0\n",
      "weights change =  0.00017441999997757154 -0.0015541939994760945\n",
      "weights =  [-0.023264107992715687, 0.1315189282076309, 0.20331480986951195, -0.010942463689589907, 0.05940423878545912, 0.0005942810109357173, -0.00026649153736230607, 0.4086565155160819, -0.16740117644373362, 0.03066264955297474, 0.02489508184194407] bias =  -0.1209403924935519\n",
      "bias change =  0.00015500000000445713\n",
      "....................................................................................................\n",
      "cycle = 1340000, errors = 29.0\n",
      "weights change =  0.00017115999997755968 -0.0015537179994760952\n",
      "weights =  [-0.023092947992738127, 0.1299652102081548, 0.20144750386977386, -0.010951073689587166, 0.05850302828556076, 0.0005808810109347196, -0.0002648915373626565, 0.4088047098582295, -0.16617015944363683, 0.02987224455292336, 0.024625851841966983] bias =  -0.12078529249354744\n",
      "bias change =  0.00015510000000446\n",
      "....................................................................................................\n",
      "cycle = 1350000, errors = 28.0\n",
      "weights change =  0.00017326999997757664 -0.0015547439994760548\n",
      "weights =  [-0.02291967799276055, 0.12841046620867874, 0.19958069787003588, -0.01095928368958443, 0.05760179288566238, 0.0005634810109337227, -0.0002606915373630072, 0.40895270857237737, -0.1649403004435402, 0.029082125552871985, 0.02435438184198993] bias =  -0.12063039249354299\n",
      "bias change =  0.00015490000000445425\n",
      "....................................................................................................\n",
      "cycle = 1360000, errors = 28.0\n",
      "weights change =  0.0001704499999775795 -0.0015547789994759809\n",
      "weights =  [-0.02274922799278297, 0.12685568720920276, 0.19771374587029777, -0.010967603689581691, 0.05670052598576397, 0.0005468810109327256, -0.00025839153736335776, 0.40910080349752515, -0.1637095864434436, 0.0282920595528206, 0.02408623184201286] bias =  -0.12047539249353853\n",
      "bias change =  0.00015500000000445713\n",
      "....................................................................................................\n",
      "cycle = 1370000, errors = 30.0\n",
      "weights change =  0.00017137999997758266 -0.0015549799994760138\n",
      "weights =  [-0.022577847992805388, 0.12530070720972675, 0.19584694987055967, -0.010975773689578954, 0.055799320685865565, 0.0005374810109317283, -0.00025289153736370826, 0.40924889928967284, -0.162479064443347, 0.027502039552769218, 0.023817161842035785] bias =  -0.12032039249353407\n",
      "bias change =  0.00015500000000445713\n",
      "....................................................................................................\n",
      "cycle = 1380000, errors = 28.0\n",
      "weights change =  0.000173519999977563 -0.001553900000055508\n",
      "weights =  [-0.022404327992827825, 0.12374680720967124, 0.19397979587082173, -0.010984523689576215, 0.05489805358596722, 0.0005188810109307312, -0.0002554915373640589, 0.4093968977268207, -0.16124917844325024, 0.02671155455271785, 0.023544741842058726] bias =  -0.12016549249352962\n",
      "bias change =  0.00015490000000445425\n",
      "....................................................................................................\n",
      "cycle = 1390000, errors = 28.0\n",
      "weights change =  0.00017183999997757993 -0.0015545590001947857\n",
      "weights =  [-0.022232487992850245, 0.12219224820947645, 0.19211279987108368, -0.010993103689573475, 0.05399674838606882, 0.000506481010929734, -0.00025619153736440944, 0.4095449930059685, -0.16001857444315362, 0.02592132255266647, 0.023276391842081655] bias =  -0.12001049249352516\n",
      "bias change =  0.00015500000000445713\n",
      "....................................................................................................\n",
      "cycle = 1400000, errors = 30.0\n",
      "weights change =  0.00017119999997757332 -0.001554524000194818\n",
      "weights =  [-0.022061287992872672, 0.12063772420928164, 0.19024572387134567, -0.011002113689570736, 0.05309543808617044, 0.0004912810109287782, -0.00025589153736476006, 0.40969289032211637, -0.15878882444305695, 0.025130918552615098, 0.02300456184210459] bias =  -0.11985569249352071\n",
      "bias change =  0.00015480000000445138\n",
      "....................................................................................................\n",
      "cycle = 1410000, errors = 30.0\n",
      "weights change =  0.00018940999997802202 -0.0015259930001899902\n",
      "weights =  [-0.02187187799289465, 0.11911173120909165, 0.18837338187160116, -0.010986403689568165, 0.05219543988627179, 0.0004691810109282501, -0.0002467915373651122, 0.40983967264626736, -0.15755201044295705, 0.024343965552564014, 0.02271233184212754] bias =  -0.1197020924935163\n",
      "bias change =  0.00015360000000441687\n",
      "....................................................................................................\n",
      "cycle = 1420000, errors = 31.0\n",
      "weights change =  0.00018640999998292482 -0.0013662800001465747\n",
      "weights =  [-0.021685467992911725, 0.11774545120894507, 0.18646260787180807, -0.010852063689566758, 0.05128680648636676, 0.0004542810109273644, -0.00024009153736540893, 0.40996053156746665, -0.1563021804428467, 0.023576455552515342, 0.022369901842151384] bias =  -0.11957499249351264\n",
      "bias change =  0.00012710000000365484\n",
      "....................................................................................................\n",
      "cycle = 1430000, errors = 29.0\n",
      "weights change =  0.00017968999998342616 -0.0013585350001426993\n",
      "weights =  [-0.0215057779929283, 0.11638691620880237, 0.18454929987201144, -0.010713193689565434, 0.05037602568646089, 0.0004397810109264691, -0.00024069153736591984, 0.41007823064267185, -0.1550541664427367, 0.022810161552466877, 0.022034361842175384] bias =  -0.11945109249350908\n",
      "bias change =  0.00012390000000356283\n",
      "....................................................................................................\n",
      "cycle = 1440000, errors = 28.0\n",
      "weights change =  0.00017828999998343795 -0.0013596230001426957\n",
      "weights =  [-0.02132748799294486, 0.11502729320865968, 0.18263637187221474, -0.010574033689564114, 0.049465320086555006, 0.0004291810109255737, -0.0002267915373667723, 0.410195731920877, -0.15380701944262679, 0.02204418255241841, 0.02169624184219939] bias =  -0.11932739249350552\n",
      "bias change =  0.00012370000000355708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 1450000, errors = 30.0\n",
      "weights change =  0.00018247999998343908 -0.0013590560001427027\n",
      "weights =  [-0.021145007992961422, 0.11366823720851697, 0.18072352987241808, -0.010434103689562792, 0.04855467998664913, 0.0004245810109246784, -0.00022399153736754067, 0.4103136315650821, -0.15255857844251686, 0.021278283552369943, 0.02136225184222339] bias =  -0.11920329249350195\n",
      "bias change =  0.00012410000000356858\n",
      "....................................................................................................\n",
      "cycle = 1460000, errors = 28.0\n",
      "weights change =  0.00017665999998343201 -0.0013591700001426843\n",
      "weights =  [-0.02096834799297799, 0.11230906720837429, 0.17881027987262138, -0.010295703689561472, 0.047643900086743254, 0.00040948101092378304, -0.00021849153736810167, 0.4104309335762873, -0.15131197644240688, 0.02051196755232148, 0.021021781842247397] bias =  -0.1190797924934984\n",
      "bias change =  0.00012350000000355132\n",
      "....................................................................................................\n",
      "cycle = 1470000, errors = 30.0\n",
      "weights change =  0.00018227999998342986 -0.0013582780001426958\n",
      "weights =  [-0.02078606799299456, 0.11095078920823159, 0.17689707987282474, -0.010156283689560147, 0.046733183986837394, 0.0004012810109228878, -0.00022249153736872876, 0.41054883246549245, -0.15006336944229687, 0.019745758552273018, 0.02068791184227139] bias =  -0.11895569249349483\n",
      "bias change =  0.00012410000000356858\n",
      "....................................................................................................\n",
      "cycle = 1480000, errors = 29.0\n",
      "weights change =  0.00017722999998344077 -0.001360033000142702\n",
      "weights =  [-0.02060883799301112, 0.10959075620808889, 0.17498426587302804, -0.01001706368955883, 0.0458225072869315, 0.0003863810109219924, -0.00021589153736935757, 0.4106662345846976, -0.148816584442187, 0.018979867552224545, 0.0203486018422954] bias =  -0.11883209249349128\n",
      "bias change =  0.0001236000000035542\n",
      "....................................................................................................\n",
      "cycle = 1490000, errors = 28.0\n",
      "weights change =  0.0001799099999834318 -0.0013583230001426444\n",
      "weights =  [-0.020428927993027687, 0.10823243320794625, 0.1730711318732312, -0.009876723689557514, 0.04491196668702564, 0.0003714810109210971, -0.00020269153736998612, 0.4107839373209026, -0.1475685724420769, 0.01821402355217608, 0.020010481842319402] bias =  -0.11870819249348771\n",
      "bias change =  0.00012390000000356283\n",
      "....................................................................................................\n",
      "cycle = 1500000, errors = 30.0\n",
      "weights change =  0.00020120999998314223 -0.001376437000144226\n",
      "weights =  [-0.020227717993044545, 0.10685599620780202, 0.17116198787343578, -0.00971819368955606, 0.0439937116871187, 0.00037028101092020146, -0.0001987915373706238, 0.41089330800911167, -0.14635313044196951, 0.017437072552127512, 0.019674691842343456] bias =  -0.11859269249348439\n",
      "bias change =  0.00011550000000332128\n",
      "....................................................................................................\n",
      "cycle = 1510000, errors = 28.0\n",
      "weights change =  0.00021260999998223146 -0.0013672210001462598\n",
      "weights =  [-0.020015107993062314, 0.10548877520765576, 0.1692394518736439, -0.009569553689554203, 0.04305811748721107, 0.0003405810109193051, -0.0001971915373712815, 0.41098813545633006, -0.14518574144186167, 0.016624904552079083, 0.019340781842367455] bias =  -0.11849179249348149\n",
      "bias change =  0.00010090000000290145\n",
      "....................................................................................................\n",
      "cycle = 1520000, errors = 29.0\n",
      "weights change =  0.0002192399999821973 -0.0013677710001464283\n",
      "weights =  [-0.019795867993080116, 0.10412100420750933, 0.1673169628738523, -0.009420103689552322, 0.042121661187303365, 0.0003268810109184087, -0.0001898915373719408, 0.4110827624455489, -0.144019375441754, 0.015811378552030658, 0.01901492184239145] bias =  -0.1183910924934786\n",
      "bias change =  0.0001007000000028957\n",
      "....................................................................................................\n",
      "cycle = 1530000, errors = 30.0\n",
      "weights change =  0.00021691999998220413 -0.0013671120001463588\n",
      "weights =  [-0.019578947993097912, 0.10275389220736297, 0.1653942228740606, -0.009271283689550448, 0.041185408187395696, 0.0003104810109175123, -0.00018429153737259973, 0.41117729095576766, -0.14285319544164618, 0.014997964552006261, 0.018684521842415442] bias =  -0.1182904924934757\n",
      "bias change =  0.00010060000000289282\n",
      "....................................................................................................\n",
      "cycle = 1540000, errors = 28.0\n",
      "weights change =  0.00021465999998222796 -0.0013680850001463185\n",
      "weights =  [-0.019364287993115684, 0.10138580720721665, 0.1634719518742688, -0.009122243689548585, 0.040249536487488025, 0.0002925810109166159, -0.00017119153737325812, 0.4112719197189862, -0.14168677244153843, 0.014185448551989013, 0.018351891842439443] bias =  -0.1181897924934728\n",
      "bias change =  0.0001007000000028957\n",
      "....................................................................................................\n",
      "cycle = 1550000, errors = 28.0\n",
      "weights change =  0.00021717999998212278 -0.0013682050001464496\n",
      "weights =  [-0.01914710799313356, 0.1000176022070702, 0.16154977887447722, -0.008973313689546712, 0.03931266938758026, 0.0002698810109157205, -0.00017149153737391944, 0.41136596016420457, -0.14052189844143131, 0.013372086551971767, 0.01802179184246347] bias =  -0.11808969249346993\n",
      "bias change =  0.00010010000000287844\n",
      "....................................................................................................\n",
      "cycle = 1560000, errors = 27.0\n",
      "weights change =  0.0002261899999809018 -0.0013702210001467485\n",
      "weights =  [-0.01892091799315266, 0.09864738120692346, 0.15963410387468643, -0.008834723689544932, 0.038370098187671696, 0.00024878101091484276, -0.00015639153737458702, 0.4114572733584137, -0.13935796144133356, 0.012565646551954544, 0.01769186184248801] bias =  -0.11799249249346713\n",
      "bias change =  9.720000000279505e-05\n",
      "....................................................................................................\n",
      "cycle = 1570000, errors = 27.0\n",
      "weights change =  0.00024805999997787667 -0.0013727470001471814\n",
      "weights =  [-0.018672857993174783, 0.09727463420677628, 0.15773513187489718, -0.008722473689543438, 0.03741490618776126, 0.00022678101091460503, -0.00015669153737524818, 0.41154292489959826, -0.13819173844125918, 0.011779472551937379, 0.01735436184251384] bias =  -0.11790139249346451\n",
      "bias change =  9.110000000261964e-05\n",
      "....................................................................................................\n",
      "cycle = 1580000, errors = 28.0\n",
      "weights change =  0.00028461999997236864 -0.0013724460001479921\n",
      "weights =  [-0.018388237993202414, 0.09590218820662828, 0.15586294087511077, -0.008660053689542408, 0.03643550158784756, 0.00019668101091454461, -0.0001418915373758771, 0.41161696273773996, -0.13702569144122573, 0.011025185551920273, 0.016998501842541952] bias =  -0.11782269249346225\n",
      "bias change =  7.870000000226307e-05\n",
      "....................................................................................................\n",
      "cycle = 1590000, errors = 27.0\n",
      "weights change =  0.00029610999997043905 -0.001391305000149362\n",
      "weights =  [-0.018092127993231975, 0.09451088320647892, 0.15400434687532694, -0.008611883689541466, 0.03544410908793201, 0.00017118101091447068, -0.00013629153737651045, 0.41168337768686925, -0.13587527944120914, 0.010278418551903281, 0.016650341842570922] bias =  -0.11775189249346021\n",
      "bias change =  7.08000000020359e-05\n",
      "....................................................................................................\n",
      "cycle = 1600000, errors = 27.0\n",
      "weights change =  0.00029653999997026476 -0.0013917280001494309\n",
      "weights =  [-0.01779558799326171, 0.09311915520632949, 0.1521464668755432, -0.008564703689540532, 0.03445168328801634, 0.0001432810109143956, -0.00012039153737708376, 0.4117490181949975, -0.13472642844119376, 0.009532017551886289, 0.01630040184259996] bias =  -0.1176818924934582\n",
      "bias change =  7.00000000020129e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 1610000, errors = 27.0\n",
      "weights change =  0.00025895999997015487 -0.0013714800001501104\n",
      "weights =  [-0.017536627993291556, 0.09174767520617938, 0.15027967187575944, -0.008482503689539778, 0.03346115088810176, 0.0001245810109142569, -0.00011169153737706067, 0.41181621343712344, -0.1335660764411766, 0.008785645551869234, 0.015959151842629273] bias =  -0.11761029249345614\n",
      "bias change =  7.16000000020589e-05\n",
      "....................................................................................................\n",
      "cycle = 1620000, errors = 30.0\n",
      "weights change =  0.00016323999996986638 -0.0013162000001518126\n",
      "weights =  [-0.01737338799332169, 0.09043147520602757, 0.1483893698759752, -0.008303063689539515, 0.03247612848819013, 0.00012198101091389987, -0.00011009153737668657, 0.4118878940172431, -0.1323739144411544, 0.008040095551852004, 0.015640231842659297] bias =  -0.11753409249345395\n",
      "bias change =  7.620000000219118e-05\n",
      "....................................................................................................\n",
      "cycle = 1630000, errors = 28.0\n",
      "weights change =  0.00016345999996966384 -0.00131246200015242\n",
      "weights =  [-0.017209927993352025, 0.08911901320587515, 0.14649601187619152, -0.008113803689539215, 0.03148807038827847, 0.00011768101091370199, -0.00010899153737630834, 0.411956886149364, -0.13118995544113207, 0.007288271551845849, 0.015324711842656706] bias =  -0.11746059249345184\n",
      "bias change =  7.350000000211354e-05\n",
      "....................................................................................................\n",
      "cycle = 1640000, errors = 27.0\n",
      "weights change =  0.0001685799999690922 -0.0013108070001541933\n",
      "weights =  [-0.017041347993382933, 0.08780820620572095, 0.14459641887641, -0.007910703689538735, 0.03048970198832703, 0.00011238101091360192, -0.00010679153737595445, 0.41201672032948977, -0.13003645644111048, 0.00651698355184444, 0.015017261842652908] bias =  -0.11739629249344999\n",
      "bias change =  6.430000000184899e-05\n",
      "....................................................................................................\n",
      "cycle = 1650000, errors = 27.0\n",
      "weights change =  0.00016861999996903992 -0.0013094740001542982\n",
      "weights =  [-0.016872727993413893, 0.08649873220556666, 0.14269581987662866, -0.007707563689540038, 0.029490466888363327, 0.00011258101091351033, -0.00010479153737560734, 0.4120757579876159, -0.12888542944108877, 0.005743741551843022, 0.014708491842649146] bias =  -0.11733279249344816\n",
      "bias change =  6.350000000182598e-05\n",
      "....................................................................................................\n",
      "cycle = 1660000, errors = 27.0\n",
      "weights change =  0.0001695299999690536 -0.0013090210001542174\n",
      "weights =  [-0.01670319799344484, 0.08518971120541244, 0.14079526387684724, -0.007505423689543073, 0.0284915391883996, 0.00010498101091341869, -0.0001016915373752429, 0.412135292323742, -0.12773265244106696, 0.004971051551841602, 0.014401831842645376] bias =  -0.11726879249344632\n",
      "bias change =  6.400000000184036e-05\n",
      "....................................................................................................\n",
      "cycle = 1670000, errors = 29.0\n",
      "weights change =  0.0001668199999690402 -0.001308605000154256\n",
      "weights =  [-0.0165363779934758, 0.08388110620525818, 0.13889422387706588, -0.007303453689546104, 0.027492376188435894, 0.00010268101091332709, -9.359153737487811e-05, 0.41219442732986816, -0.1265810644410451, 0.0041977495518401835, 0.014092491842641613] bias =  -0.1172051924934445\n",
      "bias change =  6.360000000182886e-05\n",
      "....................................................................................................\n",
      "cycle = 1680000, errors = 28.0\n",
      "weights change =  0.0001658399999690495 -0.0013086800001542581\n",
      "weights =  [-0.01637053799350675, 0.08257242620510392, 0.13699332287728444, -0.007099923689549138, 0.026493438888472196, 0.0001013810109132355, -8.99915373745135e-05, 0.41225356359599413, -0.12542946244102327, 0.003424837551847623, 0.013781381842637845] bias =  -0.11714159249344266\n",
      "bias change =  6.360000000182886e-05\n",
      "....................................................................................................\n",
      "cycle = 1690000, errors = 29.0\n",
      "weights change =  0.0002075199999668556 -0.001289492000172962\n",
      "weights =  [-0.016163017993539894, 0.08128293420493096, 0.13509279587749476, -0.006959693689552791, 0.025506382888509028, 9.458101091315922e-05, -8.87915373741288e-05, 0.41230512176809336, -0.124282174441105, 0.002682258551860253, 0.013463831842635185] bias =  -0.11708589249344106\n",
      "bias change =  5.570000000160169e-05\n",
      "....................................................................................................\n",
      "cycle = 1700000, errors = 30.0\n",
      "weights change =  0.00012313999995700042 -0.0012119370002637853\n",
      "weights =  [-0.016039877993582894, 0.08007099720466718, 0.13318440387767186, -0.006785623689559205, 0.02457777828855166, 9.648101091315021e-05, -8.829153737368827e-05, 0.41231794156406354, -0.12315519444123671, 0.0020904005518717116, 0.013184081842636631] bias =  -0.11707019249344061\n",
      "bias change =  1.5700000000451464e-05\n",
      "....................................................................................................\n",
      "cycle = 1710000, errors = 29.0\n",
      "weights change =  0.0001481499999556532 -0.001207307000273744\n",
      "weights =  [-0.01589172799362724, 0.07886369020439343, 0.1312739518778467, -0.006669583689565818, 0.023648771388594544, 9.718101091314906e-05, -8.349153737323404e-05, 0.41232223206002405, -0.12204744444136675, 0.001502463551878233, 0.012905421842638772] bias =  -0.11706319249344041\n",
      "bias change =  7.00000000020129e-06\n",
      "....................................................................................................\n",
      "cycle = 1720000, errors = 30.0\n",
      "weights change =  0.00014662999995545753 -0.0012316260002667445\n",
      "weights =  [-0.015745097993671783, 0.07763206420412669, 0.12937306387800881, -0.006553663689572289, 0.022718710088638013, 0.00010433101091314783, -7.799153737278306e-05, 0.41232378187799357, -0.1209513174415003, 0.0009468635518829865, 0.012633371842641059] bias =  -0.11705909249344029\n",
      "bias change =  4.100000000117898e-06\n",
      "....................................................................................................\n",
      "cycle = 1730000, errors = 28.0\n",
      "weights change =  0.00013188999995913768 -0.0011846820002362202\n",
      "weights =  [-0.015613207993712646, 0.07644738220389047, 0.12745812187811453, -0.006416983689578703, 0.021792603188684007, 0.00011408101091315018, -8.169153737236758e-05, 0.4123197504120045, -0.11985308844165399, 0.0005217835518851577, 0.012367121842645858] bias =  -0.11706119249344035\n",
      "bias change =  -2.100000000060387e-06\n",
      "....................................................................................................\n",
      "cycle = 1740000, errors = 31.0\n",
      "weights change =  0.00015925000003699785 -0.001172891000233739\n",
      "weights =  [-0.015453957993675648, 0.07527449120365673, 0.12552958187822713, -0.0063193436895852394, 0.020871082088728714, 0.0001193310109131539, -8.09915373719804e-05, 0.4122913387100732, -0.11882422144181161, 0.00015825555188544747, 0.012095171842655784] bias =  -0.11708789249344112\n",
      "bias change =  -2.6700000000767776e-05\n",
      "....................................................................................................\n",
      "cycle = 1750000, errors = 26.0\n",
      "weights change =  0.00015723000004378568 -0.001133006000230169\n",
      "weights =  [-0.015296727993631862, 0.07414148520342656, 0.12357637187831783, -0.006229643689591627, 0.01995512088877242, 0.00012563101091281182, -7.579153737163682e-05, 0.41223866356220257, -0.11785280344197084, -0.0001278314481146553, 0.011856011842670995] bias =  -0.11713909249344259\n",
      "bias change =  -5.120000000147229e-05\n",
      "....................................................................................................\n",
      "cycle = 1760000, errors = 32.0\n",
      "weights change =  0.00015842000004456618 -0.0011281825002184415\n",
      "weights =  [-0.015138307993587296, 0.07301330270320812, 0.1216260958783914, -0.006133943689597558, 0.01903885638881695, 0.00012818101091239436, -8.299153737130599e-05, 0.4121841676423396, -0.11688235144213381, -0.000365533448115014, 0.011604961842686135] bias =  -0.11719239249344413\n",
      "bias change =  -5.330000000153268e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 1770000, errors = 28.0\n",
      "weights change =  0.00015168000004529142 -0.0011194370002081955\n",
      "weights =  [-0.014986627993542005, 0.07189386570299992, 0.11967599187846789, -0.00603562368960311, 0.018122438688862267, 0.00013218101091205548, -7.639153737098726e-05, 0.4121291983664832, -0.11590697344229996, -0.0005594654481140481, 0.011358681842701198] bias =  -0.11724639249344568\n",
      "bias change =  -5.4000000001552806e-05\n",
      "....................................................................................................\n",
      "cycle = 1780000, errors = 31.0\n",
      "weights change =  0.00015204000004650012 -0.0011175345001891573\n",
      "weights =  [-0.014834587993495504, 0.07077633120281077, 0.11773210787854999, -0.0059436936896079175, 0.01720510078890886, 0.00012993101091170444, -8.12915373706878e-05, 0.4120716756826397, -0.11493212344247189, -0.0006725704481124335, 0.01110601184271609] bias =  -0.11730339249344732\n",
      "bias change =  -5.700000000163907e-05\n",
      "....................................................................................................\n",
      "cycle = 1790000, errors = 31.0\n",
      "weights change =  0.0001495400000466468 -0.0011232135001860433\n",
      "weights =  [-0.014685047993448858, 0.06965311770262472, 0.115790893878633, -0.00586087368961259, 0.016287238888955637, 0.00012593101091134328, -9.759153737039061e-05, 0.4120135255267987, -0.11395873844264454, -0.0007709544481108399, 0.010857281842730911] bias =  -0.11736109249344898\n",
      "bias change =  -5.77000000016592e-05\n",
      "....................................................................................................\n",
      "cycle = 1800000, errors = 31.0\n",
      "weights change =  0.000156420000046658 -0.00112331500018574\n",
      "weights =  [-0.0145286279934022, 0.06852980270243898, 0.11385034487871616, -0.00577874368961725, 0.015369398188982017, 0.00013208101091097762, -7.639153737009331e-05, 0.41195568370095786, -0.11298458044281733, -0.0008681094481092486, 0.010611051842745738] bias =  -0.11741849249345063\n",
      "bias change =  -5.7400000001650575e-05\n",
      "....................................................................................................\n",
      "cycle = 1810000, errors = 28.0\n",
      "weights change =  0.00017181000004668628 -0.0011288205001841328\n",
      "weights =  [-0.014356817993355513, 0.06740098220225485, 0.11191279487880013, -0.00571489368962187, 0.014450927388955427, 0.0001292310109106168, -7.509153736979466e-05, 0.4118968735051205, -0.11201459644298983, -0.0009605624481076628, 0.010363231842760699] bias =  -0.1174768924934523\n",
      "bias change =  -5.840000000167933e-05\n",
      "....................................................................................................\n",
      "cycle = 1820000, errors = 31.0\n",
      "weights change =  0.00019810000004693955 -0.0011634855001735889\n",
      "weights =  [-0.014158717993308574, 0.06623749670208126, 0.10998771787888846, -0.005721843689626336, 0.013525888088928937, 0.00011373101091030896, -9.349153736949495e-05, 0.41182443985531886, -0.11108939644315395, -0.0010287444481049883, 0.010117181842777259] bias =  -0.11754899249345438\n",
      "bias change =  -7.210000000207328e-05\n",
      "....................................................................................................\n",
      "cycle = 1830000, errors = 30.0\n",
      "weights change =  0.0001844800000475183 -0.0011279920001684568\n",
      "weights =  [-0.013974237993261055, 0.0651095047019128, 0.1080475768789784, -0.005679213689631036, 0.012597715488904336, 0.00010598101091034759, -7.61915373692064e-05, 0.41174215636354905, -0.11018283344330758, -0.001105446448101981, 0.009890761842795987] bias =  -0.11763079249345673\n",
      "bias change =  -8.180000000235221e-05\n",
      "....................................................................................................\n",
      "cycle = 1840000, errors = 30.0\n",
      "weights change =  0.00018864000004815105 -0.0011291175001562487\n",
      "weights =  [-0.013785597993212904, 0.06398038720175656, 0.10610571987907282, -0.005641913689635794, 0.011661674488881394, 0.00011323101091041885, -7.679153736892664e-05, 0.4116398129378333, -0.10933186044344574, -0.0011716524480989894, 0.009670421842817748] bias =  -0.11773259249345966\n",
      "bias change =  -0.00010180000000292733\n",
      "....................................................................................................\n",
      "cycle = 1850000, errors = 30.0\n",
      "weights change =  0.00019596000004852392 -0.0010717940001561954\n",
      "weights =  [-0.01358963799316438, 0.06290859320160036, 0.10414310587916484, -0.0056252736896406025, 0.010726107688859607, 0.00010298101091049666, -7.369153736865468e-05, 0.41153587628212707, -0.10847112744357768, -0.001249345448095967, 0.009450261842840566] bias =  -0.11783589249346263\n",
      "bias change =  -0.00010330000000297046\n",
      "....................................................................................................\n",
      "cycle = 1860000, errors = 30.0\n",
      "weights change =  0.00020670000004882096 -0.001122756500047499\n",
      "weights =  [-0.01338293799311556, 0.06178583670155286, 0.10219681087926118, -0.005642813689645172, 0.00977988228883872, 9.61310109105894e-05, -6.529153736838805e-05, 0.411408856672479, -0.10768397044369268, -0.0012991314480930178, 0.00925736184286604] bias =  -0.11796229249346626\n",
      "bias change =  -0.00012640000000363472\n",
      "....................................................................................................\n",
      "cycle = 1870000, errors = 29.0\n",
      "weights change =  0.00023166000004902834 -0.0010887969999950342\n",
      "weights =  [-0.013151277993066531, 0.06069703970155783, 0.10024037087935529, -0.005653113689649669, 0.008833315488818685, 9.133101091068797e-05, -6.569153736813211e-05, 0.4112773990968415, -0.10690347244380155, -0.0013584914480900471, 0.009045301842892473] bias =  -0.11809309249347003\n",
      "bias change =  -0.00013080000000376124\n",
      "....................................................................................................\n",
      "cycle = 1880000, errors = 30.0\n",
      "weights change =  0.0002348300000488794 -0.00109262499999601\n",
      "weights =  [-0.012916447993017652, 0.05960441470156182, 0.09828535187944679, -0.005686813689653951, 0.007885905788798622, 8.453101091078887e-05, -8.029153736791275e-05, 0.4111439519512055, -0.10612844344390716, -0.0014154904480870889, 0.008834581842918875] bias =  -0.11822589249347384\n",
      "bias change =  -0.00013280000000381875\n",
      "............................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m_cython_magic_1e27bc5b740c3dceca2c106e046bbc95.pyx\u001b[0m in \u001b[0;36minit _cython_magic_1e27bc5b740c3dceca2c106e046bbc95\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_cython_magic_1e27bc5b740c3dceca2c106e046bbc95.pyx\u001b[0m in \u001b[0;36m_cython_magic_1e27bc5b740c3dceca2c106e046bbc95.train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_cython_magic_1e27bc5b740c3dceca2c106e046bbc95.pyx\u001b[0m in \u001b[0;36m_cython_magic_1e27bc5b740c3dceca2c106e046bbc95.display\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-94da1d5bbc8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cython'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'import pandas as pd\\nfrom libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\\nfrom cpython cimport array\\nimport array\\n\\nred_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=\\';\\')\\ndata = red_wine[(red_wine[\\'quality\\'] >= 7) | (red_wine[\\'quality\\'] <= 4)].reset_index()\\ny = [1 if i == True else 0 for i in data[\\'quality\\'] >= 8]\\ndata = data[[\\'fixed acidity\\', \\'volatile acidity\\', \\'citric acid\\', \\'residual sugar\\',\\n       \\'chlorides\\', \\'free sulfur dioxide\\', \\'total sulfur dioxide\\', \\'density\\',\\n       \\'pH\\', \\'sulphates\\', \\'alcohol\\']].values.tolist()\\n\\ndef display(ret, dot=100, detail=10000, final=False):\\n    \"\"\"Displays text info about training process\"\"\"\\n    if final:\\n        print()\\n        print(\\'DONE\\')\\n        print(\\'cycle = \\', ret[-1][0], \\', errors = \\', ret[-1][1], sep=\\'\\')\\n        print(\\'final weights = \\', ret[-1][2], \\', bias = \\', ret[-1][3])\\n    if ret[-1][0] == 0:\\n        return\\n    if ret[-1][0] % dot == 0:\\n        print(\\'.\\', end=\\'\\')\\n    if ret[-1][0] % detail == 0:\\n        print()\\n        print(\\'cycle = \\', ret[-1][0], \\', errors = \\', ret[-1][1], sep=\\'\\')\\n        \\n#         print(ret[-1])\\n        print(\\'weights change = \\', ret[-1][2][0] - ret[-detail - 1][2][0],\\n              ret[-1][2][1] - ret[-detail - 1][2][1])\\n        print(\\'weights = \\', ret[-1][2], \\'bias = \\', ret[-1][3])\\n        print(\\'bias change = \\', ret[-1][3] - ret[-detail - 1][3])\\n        \\ncdef struct s_perceptron:\\n    double *weights;\\n    double bias;\\n    int amount;\\nctypedef s_perceptron t_perceptron\\n\\ncdef t_perceptron init_perceptron(int amount):\\n    srand(42)\\n    cdef t_perceptron ret\\n    ret.amount = amount\\n    ret.weights = <double *>malloc(sizeof(double) * amount)\\n    ret.bias = <double>rand() / RAND_MAX\\n#     ret.bias = 0.27502931836911926\\n#     ret.weights[0] = 0.6394267984578837\\n#     ret.weights[1] = 0.025010755222666936\\n    for i in range(amount):\\n        ret.weights[i] = <double>rand() / RAND_MAX\\n        print(\\'Weights[\\', i, \\'] = \\', ret.weights[i], sep=\\'\\')\\n    print(\\'bias = \\', ret.bias, \\'\\\\n\\')\\n    return ret\\n    \\ncdef int activation(double value):\\n    return 1 if value > 0 else 0\\n    \\ncdef double predict(t_perceptron *model, list data, double alpha, int y):\\n    cdef double rez = model.bias\\n    for i in range(model.amount):\\n        rez += data[i] * model.weights[i]\\n    tmp = rez\\n    rez = activation(rez)\\n    if y == -1:\\n        return activation(rez)\\n    if rez != y:\\n        for i in range(model.amount):\\n            model.weights[i] += alpha * data[i] * (y - rez)\\n        model.bias += alpha * (y - rez)\\n    return rez != y\\n\\ncdef list train(t_perceptron model, list data, list y, int epochs, double alpha):\\n    cdef list ret = []\\n    cdef double errors = 1\\n    cdef unsigned long i = 0\\n    if epochs == 0:\\n        while (errors):\\n            errors = 0\\n            for j, item in enumerate(data):\\n                errors += predict(&model, item, alpha, y[j])\\n            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\\n                        model.bias])\\n            i += 1\\n            display(ret)\\n        display(ret, final=True)\\n    else:\\n        for i in range(epochs):\\n            errors = 0\\n            for j, item in enumerate(data):\\n                errors += predict(&model, item, alpha, y[j])\\n            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\\n                        model.bias])\\n            display(ret)\\n            if errors == 0:\\n                break\\n        display(ret, final=True)\\n    return ret\\n\\ncdef t_perceptron model = init_perceptron(11)\\ntrain(model, data, y, 10000000, 0.0000001)\\nfree(model.weights)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2165\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-127>\u001b[0m in \u001b[0;36mcython\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.brew/lib/python3.7/site-packages/Cython/Build/IpythonMagic.py\u001b[0m in \u001b[0;36mcython\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    329\u001b[0m                               quiet=args.quiet)\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_import_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/imp.py\u001b[0m in \u001b[0;36mload_dynamic\u001b[0;34m(name, path, file)\u001b[0m\n\u001b[1;32m    341\u001b[0m         spec = importlib.machinery.ModuleSpec(\n\u001b[1;32m    342\u001b[0m             name=name, loader=loader, origin=path)\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.brew/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\n",
    "from cpython cimport array\n",
    "import array\n",
    "\n",
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')\n",
    "data = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index()\n",
    "y = [1 if i == True else 0 for i in data['quality'] >= 8]\n",
    "data = data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values.tolist()\n",
    "\n",
    "def process_to_poly(data):\n",
    "    poly = data.values.tolist()\n",
    "    length = len(tmp[0])\n",
    "    for line in pan_gal_poly:\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                line.append(line[i] * line[j])\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                for k in range(length):\n",
    "                    line.append(line[i] * line[j] * line[k])\n",
    "    print('Was:', length, 'Now:', len(pan_gal_poly[0]))\n",
    "    return poly\n",
    "data = \n",
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('final weights = ', ret[-1][2], ', bias = ', ret[-1][3])\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('weights change = ', ret[-1][2][0] - ret[-detail - 1][2][0],\n",
    "              ret[-1][2][1] - ret[-detail - 1][2][1])\n",
    "        print('weights = ', ret[-1][2], 'bias = ', ret[-1][3])\n",
    "        print('bias change = ', ret[-1][3] - ret[-detail - 1][3])\n",
    "        \n",
    "cdef struct s_perceptron:\n",
    "    double *weights;\n",
    "    double bias;\n",
    "    int amount;\n",
    "ctypedef s_perceptron t_perceptron\n",
    "\n",
    "cdef t_perceptron init_perceptron(int amount):\n",
    "    srand(42)\n",
    "    cdef t_perceptron ret\n",
    "    ret.amount = amount\n",
    "    ret.weights = <double *>malloc(sizeof(double) * amount)\n",
    "    ret.bias = <double>rand() / RAND_MAX\n",
    "#     ret.bias = 0.27502931836911926\n",
    "#     ret.weights[0] = 0.6394267984578837\n",
    "#     ret.weights[1] = 0.025010755222666936\n",
    "    for i in range(amount):\n",
    "        ret.weights[i] = <double>rand() / RAND_MAX\n",
    "        print('Weights[', i, '] = ', ret.weights[i], sep='')\n",
    "    print('bias = ', ret.bias, '\\n')\n",
    "    return ret\n",
    "    \n",
    "cdef int activation(double value):\n",
    "    return 1 if value > 0 else 0\n",
    "    \n",
    "cdef double predict(t_perceptron *model, list data, double alpha, int y):\n",
    "    cdef double rez = model.bias\n",
    "    for i in range(model.amount):\n",
    "        rez += data[i] * model.weights[i]\n",
    "    tmp = rez\n",
    "    rez = activation(rez)\n",
    "    if y == -1:\n",
    "        return activation(rez)\n",
    "    if rez != y:\n",
    "        for i in range(model.amount):\n",
    "            model.weights[i] += alpha * data[i] * (y - rez)\n",
    "        model.bias += alpha * (y - rez)\n",
    "    return rez != y\n",
    "\n",
    "cdef list train(t_perceptron model, list data, list y, int epochs, double alpha):\n",
    "    cdef list ret = []\n",
    "    cdef double errors = 1\n",
    "    cdef unsigned long i = 0\n",
    "    if epochs == 0:\n",
    "        while (errors):\n",
    "            errors = 0\n",
    "            for j, item in enumerate(data):\n",
    "                errors += predict(&model, item, alpha, y[j])\n",
    "            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias])\n",
    "            i += 1\n",
    "            display(ret)\n",
    "        display(ret, final=True)\n",
    "    else:\n",
    "        for i in range(epochs):\n",
    "            errors = 0\n",
    "            for j, item in enumerate(data):\n",
    "                errors += predict(&model, item, alpha, y[j])\n",
    "            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias])\n",
    "            display(ret)\n",
    "            if errors == 0:\n",
    "                break\n",
    "        display(ret, final=True)\n",
    "    return ret\n",
    "\n",
    "cdef t_perceptron model = init_perceptron(11)\n",
    "train(model, data, y, 10000000, 0.0000001)\n",
    "free(model.weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
