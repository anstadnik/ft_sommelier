{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.1 Exploring the green reds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter_matrix(wine_data, good_threshhold, bad_threshold, save_plot=False):\n",
    "    \"\"\"Visualizes the data\n",
    "    \"\"\"\n",
    "    length = len(wine_data.columns)\n",
    "    fig, ax = plt.subplots(length, length, figsize=(50, 50))\n",
    "    bigger = wine_data.where(wine_data['quality'] > good_threshhold)\n",
    "    smaller = wine_data.where(wine_data['quality'] < bad_threshold)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(length):\n",
    "            if i == j:\n",
    "                ax[(i, j)].text(0.5, 0.5, '\\n'.join(wine_data.columns[i].split()), fontsize=35, ha='center', va='center')\n",
    "            else:\n",
    "                ax[(j, i)].plot(bigger.iloc[:, i], bigger.iloc[:, j], 'co')\n",
    "                ax[(j, i)].plot(smaller.iloc[:, i], smaller.iloc[:, j], 'mo')\n",
    "    if save_plot:\n",
    "        plt.savefig('scatter_matrix.png')\n",
    "# plot_scatter_matrix(red_wine, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_scatter_matrix(red_wine, 7, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "\n",
    "I think it can be pH, sulphates, alcohol and total sulfur dioxide. Cause there\n",
    "different\n",
    "groups of wine(based on quality) r better splitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.2 Learning to perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3_8 = red_wine[(red_wine['quality'] >= 8) | (red_wine['quality'] <= 3)].reset_index(drop=True)\n",
    "y_3_8 = [1 if i == True else 0 for i in data_3_8['quality'] >= 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('final weights = ', ret[-1][2], ', bias = ', ret[-1][3])\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        print('weights change = ', ret[-1][2][0] - ret[-detail - 1][2][0], ret[-1][2][1] - ret[-detail - 1][2][1])\n",
    "        print('weights = ', ret[-1][2], 'bias = ', ret[-1][3])\n",
    "        print('bias change = ', ret[-1][3] - ret[-detail - 1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays info when model is learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class perceptron:\n",
    "    \"\"\"A simple perceptron, with randomly initialized weights and bias\"\"\"\n",
    "\n",
    "    def __init__(self, amount):\n",
    "        \"\"\"Random data initialization\"\"\"\n",
    "        random.seed(42)\n",
    "        self.amount = amount\n",
    "        self.weights = [random.random() for n in range(amount)]\n",
    "        self.bias = random.random()\n",
    "        for i in range(amount):\n",
    "            print('Weights[', i, '] = ', self.weights[i], sep='')\n",
    "        print('bias = ', self.bias, '\\n')\n",
    "\n",
    "    def activation(self, value):\n",
    "        \"\"\"Activation function\"\"\"\n",
    "        return 1 if value > 0 else 0\n",
    "\n",
    "    def predict(self, data, alpha = None, y = None):\n",
    "        \"\"\"Predicts answer and updates weights to fit the data item better\n",
    "        Returns predicted value or whether he guessed right\n",
    "        \"\"\"\n",
    "        rez = self.activation(sum([data[i] * self.weights[i]\n",
    "                                   for i in range(self.amount)]) + self.bias)\n",
    "        if y == None:\n",
    "            return rez\n",
    "        if rez != y:\n",
    "            self.weights = [self.weights[i] + alpha * data[i] * (y - rez) \n",
    "                            for i in range(self.amount)]\n",
    "            self.bias = self.bias + alpha * (y - rez)\n",
    "        return rez != y\n",
    "\n",
    "    def train(self, data, y, epochs = 0, alpha = 0.001):\n",
    "        \"\"\"Trains perceptron epoch times, and logs results\"\"\"\n",
    "        ret = []\n",
    "        errors = 1\n",
    "        if epochs == 0:\n",
    "            i = 0\n",
    "            while (errors):\n",
    "                errors = 0\n",
    "                for item in data.itertuples():\n",
    "                    errors += self.predict(item[1:], alpha, y[item[0]])\n",
    "                ret.append([i, errors, self.weights, self.bias])\n",
    "                i += 1\n",
    "                display(ret)\n",
    "            display(ret, final=True)\n",
    "        else:\n",
    "            for i in range(epochs):\n",
    "                errors = 0\n",
    "                for item in data.itertuples():\n",
    "                    errors += self.predict(item[1:], alpha, y[item[0]])\n",
    "                ret.append([i, errors, self.weights, self.bias])\n",
    "                display(ret)\n",
    "                if errors == 0:\n",
    "                    break\n",
    "            display(ret, final=True)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.6394267984578837\n",
      "Weights[1] = 0.025010755222666936\n",
      "bias =  0.27502931836911926 \n",
      "\n",
      "....................................................................................................\n",
      "cycle = 10000, errors = 2\n",
      "weights change =  -7.069099999996053 1.848000000000045\n",
      "weights =  [-6.536073201538169, 1.653510755222712] bias =  4.455029318369069\n",
      "bias change =  4.209999999999949\n",
      "...............................\n",
      "DONE\n",
      "cycle = 13154, errors = 0\n",
      "final weights =  [-7.259373201536793, 1.731510755222712] , bias =  6.135029318369033\n"
     ]
    }
   ],
   "source": [
    "model = perceptron(2)\n",
    "logs = model.train(data_3_8[['pH', 'alcohol']], y_3_8, 0, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) && bonus V.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(performance, wine_data, good_threshold, bad_threshold, epoch=-1, save_plot=False, debug=False):\n",
    "    \"\"\"Plot the performance of my perceptron\"\"\"\n",
    "    if debug:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(30, 30))\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 2)#, figsize=(10, 10))\n",
    "    bigger = wine_data.where(wine_data['quality'] > good_threshold).reset_index(drop=True)\n",
    "    smaller = wine_data.where(wine_data['quality'] < bad_threshold).reset_index(drop=True)\n",
    "    \n",
    "    ax[0].plot([i[1] for i in performance], 'g')\n",
    "    ax[0].set_title('Errors as a function of epoch')\n",
    "    ax[0].set_ylabel('Classification errors')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[1].plot(bigger['alcohol'], bigger['pH'], 'mo', label = 'good wines (> ' + str(good_threshold) + ' score)')\n",
    "    ax[1].plot(smaller['alcohol'], smaller['pH'], 'co', label = 'bad wines (< ' + str(bad_threshold) + ' score)')\n",
    "    ax[1].set_title('Decision boundary on epoch:' + str(len(performance) if epoch == -1 else epoch))\n",
    "    ax[1].set_xlabel('Alcohol')\n",
    "    ax[1].set_ylabel('pH')\n",
    "    \n",
    "    val = {}\n",
    "    if debug:\n",
    "        val['alcohol'] = [-100, 100]         \n",
    "    else:\n",
    "#         val['alcohol'] = [5, 15]         \n",
    "        val['alcohol'] = [min(wine_data['alcohol']) - 1, max(wine_data['alcohol']) + 1] \n",
    "    val['pH'] = [\n",
    "            - (performance[epoch][2][1] * val['alcohol'][0] + performance[epoch][3]) / performance[epoch][2][0],\n",
    "            - (performance[epoch][2][1] * val['alcohol'][1] + performance[epoch][3]) / performance[epoch][2][0]\n",
    "        ]\n",
    "    ax[1].plot(val['alcohol'], val['pH'], 'g--')\n",
    "    if debug:\n",
    "        ax[1].set_xlim(-100, 100)\n",
    "        ax[1].set_ylim(-100, 100)\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], -100, facecolor='#f8bbd0')\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], 100, facecolor='#b2ebf2')\n",
    "    else:\n",
    "#         ax[1].set_xlim(5, 15)\n",
    "#         ax[1].set_ylim(2, 5)\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], -5, facecolor='#f8bbd0')\n",
    "        ax[1].fill_between(val['alcohol'], val['pH'], 15, facecolor='#b2ebf2')\n",
    "        ax[1].set_xlim(min(wine_data['alcohol']) - 1, max(wine_data['alcohol']) + 1)\n",
    "        ax[1].set_ylim(min(wine_data['pH']) - 1, max(wine_data['pH']) + 1)\n",
    "#         ax[1].fill_between(val['alcohol'], val['pH'], min(wine_data['pH']), facecolor='#b2ebf2')\n",
    "#         ax[1].fill_between(val['alcohol'], val['pH'], max(wine_data['pH']), facecolor='#f8bbd0')\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(1.6, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "565d090253dc4d45afa03fb1f6c3384d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(logs), wine_data=fixed(red_wine), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(logs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "normalized_red_wine = red_wine.copy()\n",
    "for title in red_wine.columns:\n",
    "    if not title == 'quality':\n",
    "        normalized_red_wine[title] = (red_wine[title] - min(red_wine[title])) / (max(red_wine[title]) - min(red_wine[title]))\n",
    "normalized_data_3_8 = normalized_red_wine[(red_wine['quality'] >= 8) | (red_wine['quality'] <= 3)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights[0] = 0.6394267984578837\n",
      "Weights[1] = 0.025010755222666936\n",
      "bias =  0.27502931836911926 \n",
      "\n",
      "\n",
      "DONE\n",
      "cycle = 85, errors = 0\n",
      "final weights =  [-0.09521887083345507, 0.10070306291497405] , bias =  0.015029318369119145\n"
     ]
    }
   ],
   "source": [
    "model_normalized = perceptron(2)\n",
    "logs_normalized = model_normalized.train(normalized_data_3_8[['pH', 'alcohol']], y_3_8, 0, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978bd799d6f34bf8aab515bf67cefe01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(logs_normalized), wine_data=fixed(normalized_red_wine), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(logs_normalized) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.3 My fair ADALINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using stochastic learning algorithm instead of batch. Not adding polynomial features and not using more complicated algorhithms. No parallelism. Using only labels in learning, not values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b), c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaline:\n",
    "    \"\"\"A simple adaline, with randomly initialized weights and bias\"\"\"\n",
    "\n",
    "    def __init__(self, amount):\n",
    "        \"\"\"Random data initialization\"\"\"\n",
    "        self.amount = amount\n",
    "        self.weights = [random.random() for n in range(amount)]\n",
    "        self.bias = random.random()\n",
    "\n",
    "        \n",
    "    def quantizer(self, value):\n",
    "        \"\"\"Quantizer function\"\"\"\n",
    "        return 1 if value > 5.6 else 0\n",
    "\n",
    "    \n",
    "    def predict(self, data, y=False):\n",
    "        \"\"\"Predicts answer and updates weights to fit the data item better\n",
    "        Returns predicted value or whether he guessed right\n",
    "        \"\"\"\n",
    "        rez = sum([data[i] * self.weights[i] for i in range(self.amount)]) + self.bias\n",
    "        if y == False:\n",
    "            return self.quantizer(rez)\n",
    "        else:\n",
    "            err = y - rez\n",
    "#             print('y =', y, 'rez =', rez, 'y - rez =', y - rez)\n",
    "            return [[x * err for x in [*data, 1]], err]\n",
    "        \n",
    "    def train(self, data, y, epochs = 0, alpha = 0.001):\n",
    "        \"\"\"Trains perceptron epoch times, and logs results\"\"\"\n",
    "        ret = []\n",
    "        if epochs == 0:\n",
    "            i = 0\n",
    "            while (True):\n",
    "                error = 0\n",
    "                delta = [0] * (self.amount + 1)\n",
    "                for item in data.itertuples():\n",
    "                    [rez, err] = self.predict(item[1:], y[item[0]])\n",
    "                    delta = [delta[i] + rez[i] for i in range(self.amount + 1)]\n",
    "                    error += err\n",
    "                self.weights = [self.weights[i] + alpha * delta[i] / len(data) for i in range(self.amount)]\n",
    "                self.bias += alpha * delta[-1] / len(data)\n",
    "                ret.append([i, error, self.weights, self.bias - 5])\n",
    "                display(ret)\n",
    "                if i > 0 and abs(ret[-1][1] - error) < 0.0000000001:\n",
    "                    break\n",
    "                i += 1\n",
    "            display(ret, final=True)\n",
    "        else:\n",
    "            for i in range(epochs):\n",
    "                error = 0\n",
    "                delta = [0] * (self.amount + 1)\n",
    "                for item in data.itertuples():\n",
    "                    [rez, err] = self.predict(item[1:], y[item[0]])\n",
    "                    delta = [delta[i] + rez[i] for i in range(self.amount + 1)]\n",
    "                    error += err ** 2\n",
    "#                 print(delta, errors)\n",
    "                self.weights = [self.weights[i] + alpha * delta[i] / len(data) for i in range(self.amount)]\n",
    "                self.bias += alpha * delta[-1] / len(data)\n",
    "                ret.append([i, error, self.weights, self.bias - 5.6])\n",
    "                display(ret)\n",
    "                if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                    print(ret[-1], error)\n",
    "                    break\n",
    "            display(ret, final=True)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4_7 = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index(drop=True)\n",
    "y_4_7 = data_4_7['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 10000, errors = 376.3190315150191\n",
      "weights change =  -0.8404198411323816 -0.004786962845589771\n",
      "weights =  [-0.6283195699388097, 0.6941690043010255] bias =  -4.965177617498963\n",
      "bias change =  -0.03854816030050223\n",
      "....................................................................................................\n",
      "cycle = 20000, errors = 370.32087159529937\n",
      "weights change =  -0.2892037488245931 0.07534763244576803\n",
      "weights =  [-0.9175233187634028, 0.7695166367467935] bias =  -4.860253452933253\n",
      "bias change =  0.10492416456570997\n",
      "...................................................................................................\n",
      "DONE\n",
      "cycle = 29999, errors = 368.1941398158499\n",
      "final weights =  [-1.0436300088856048, 0.7937042475813745] , bias =  -4.716316565374624\n"
     ]
    }
   ],
   "source": [
    "model = adaline(2)\n",
    "adaline_logs = model.train(data_4_7[['pH', 'alcohol']], y_4_7.tolist(), 30000, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454c342e436c4f49b660b91b9ff4dee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(adaline_logs), wine_data=fixed(data_4_7), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(adaline_logs) - 1), debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_4_7 = normalized_red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................[8282, 329.9624293840112, [-4.001871819199307, 4.712259300674113], 0.5024108813615573] 329.9624293840112\n",
      "\n",
      "DONE\n",
      "cycle = 8282, errors = 329.9624293840112\n",
      "final weights =  [-4.001871819199307, 4.712259300674113] , bias =  0.5024108813615573\n"
     ]
    }
   ],
   "source": [
    "model = adaline(2)\n",
    "adaline_logs_normalized = model.train(normalized_data_4_7[['pH', 'alcohol']], y_4_7.tolist(), 30000, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 / 280\n"
     ]
    }
   ],
   "source": [
    "pred = [model.predict(normalized_data_4_7.loc[i, ['pH', 'alcohol']]) for i in range(len(normalized_data_4_7))]\n",
    "y = [1 if i == True else 0 for i in normalized_data_4_7['quality'] >= 7]\n",
    "\n",
    "print(sum([abs((y[i] - pred[i])) for i in range(len(y))]), '/', len(normalized_data_4_7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5854c46fad9e4a85b8d4be30a77bafeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='good_threshold', max=10), IntSlider(value=5, description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive(plot_performance, performance=fixed(adaline_logs_normalized), wine_data=fixed(normalized_data_4_7), good_threshold=(0, 10),\\\n",
    "            bad_threshold=(0, 10), epoch=(0, len(adaline_logs_normalized) - 1), debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout(input_data, percentage=30):\n",
    "    data = input_data.sample(frac=1).reset_index(drop=True)\n",
    "    sep = int(len(data) * percentage / 100)\n",
    "    return (data[:sep], data[sep:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 84 196\n"
     ]
    }
   ],
   "source": [
    "train, test = holdout(normalized_data_4_7)\n",
    "print(len(normalized_data_4_7), len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_folds(input_data, k=10, shuffle=False):\n",
    "    data = input_data.sample(frac=1).reset_index(drop=True) if shuffle else input_data\n",
    "    seps = [int(len(data) / k) * i for i in range(k + 1)]\n",
    "    parts = []\n",
    "    for i in range(k):\n",
    "        parts.append(data[seps[i]:seps[i + 1]])\n",
    "    ret = []\n",
    "    for i in range(k):\n",
    "        train = pd.concat([parts[j] for j in range(k) if not j == i]).reset_index()\n",
    "        test = parts[i].reset_index()\n",
    "        ret.append((train, test))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n",
      "280 252 28\n"
     ]
    }
   ],
   "source": [
    "data = k_folds(normalized_data_4_7)\n",
    "for train, test in data:\n",
    "    print(len(normalized_data_4_7), len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(input_data, k=10, epochs=10000, alpha=0.01):\n",
    "    data = k_folds(input_data)\n",
    "    error = []\n",
    "    logs = []\n",
    "    for train, test in data:\n",
    "        model = adaline(2)\n",
    "        log = model.train(train[['pH', 'alcohol']], train['quality'].tolist(), epochs, alpha)\n",
    "        logs.append(log)\n",
    "        y = [1 if i == True else 0 for i in train['quality'] >= 7]\n",
    "        pred = [model.predict(train.loc[i, ['pH', 'alcohol']]) for i in range(len(train))]\n",
    "        error.append(sum([abs(y[i] - pred[i]) for i in range(len(y))]))\n",
    "    return (sum(error) / k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adaline trains it predicts continious value. It compares 4 vs 5 as example while we're inspecting model we compare binary values (1 vs 0). That's why values differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 393.0261194159426\n",
      "final weights =  [1.1821076861292337, 2.6053538603261583] , bias =  -0.8813514640286391\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 432.11925917258105\n",
      "final weights =  [1.0911196627093578, 2.5194950134024348] , bias =  -0.9088844334766106\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 444.4833581032538\n",
      "final weights =  [1.5268554568414145, 2.4372932260027147] , bias =  -1.069997115020084\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 422.93475327930724\n",
      "final weights =  [1.7161127094111663, 2.2104733314604474] , bias =  -0.9395797951096254\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 431.94518895415655\n",
      "final weights =  [1.7095856853008768, 2.618144986749313] , bias =  -1.1371382480905448\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 480.24718238365745\n",
      "final weights =  [1.8685604347011997, 2.606599747435001] , bias =  -1.2671831262366844\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 437.864285045972\n",
      "final weights =  [1.046045926254339, 2.9337660395286465] , bias =  -1.0654673362965692\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 449.6701903444032\n",
      "final weights =  [1.6963005376328537, 2.7606486804736257] , bias =  -1.2454399101221565\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 405.7225108426852\n",
      "final weights =  [1.8142657586924227, 2.5230622505604443] , bias =  -1.0942161049336425\n",
      ".........\n",
      "DONE\n",
      "cycle = 999, errors = 404.65266379399543\n",
      "final weights =  [1.6377666533754052, 2.59857138636565] , bias =  -1.0785616649834617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53.4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(normalized_data_4_7, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.5 Adventures in the Nth dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) && bonus V.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 10000, errors = 251.48320672233177\n",
      "weights change =  0.8650463175650619 -3.1352193064615763\n",
      "weights =  [1.4606386452854836, -2.419700162349958, 0.780622025578617, -0.3846644806468307, -0.9119778929294038, 0.5202652125570416, -0.305392952427557, -0.39789054263478746, 0.6145963864552819, 2.153337179790007, 3.520473708010793] bias =  -1.4692799127790446\n",
      "bias change =  3.710359287266349\n",
      "....................................................................................................\n",
      "cycle = 20000, errors = 236.93240073088967\n",
      "weights change =  -0.012849754707971783 -0.702157034756512\n",
      "weights =  [1.4477888905775118, -3.12185719710647, 0.09268209151867608, -0.5195233421844885, -1.5574192826342521, 0.6108005248942, -0.5853994691999379, -0.2729343254655107, -0.027957246119080285, 2.316622099847868, 3.462988536178477] bias =  -0.7375753657923907\n",
      "bias change =  0.7317045469866539\n",
      "...................................................................................................\n",
      "DONE\n",
      "cycle = 29999, errors = 231.80915850936688\n",
      "final weights =  [1.2924172381988952, -3.3759464921991915, -0.25952345835106044, -0.5118000555713178, -1.9413337526413093, 0.6845538426488971, -0.7174325671964733, -0.10692920388645015, -0.5770146890926396, 2.3920444171166544, 3.4917895213767816] , bias =  -0.31574997844667685\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\n",
    "from cpython cimport array\n",
    "import array\n",
    "\n",
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')\n",
    "\n",
    "data_4_7 = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index()\n",
    "y_4_7 = data_4_7['quality'].tolist()\n",
    "normalized_data_4_7 = data_4_7.copy()\n",
    "for column in normalized_data_4_7.columns:\n",
    "    if column != 'quality':\n",
    "        normalized_data_4_7[column] = (data_4_7[column] - min(data_4_7[column])) / (max(data_4_7[column]) - min(data_4_7[column]))\n",
    "data = normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values.tolist()\n",
    "        \n",
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        \n",
    "cdef struct s_perceptron:\n",
    "    double *weights;\n",
    "    double bias;\n",
    "    int amount;\n",
    "ctypedef s_perceptron t_perceptron\n",
    "\n",
    "cdef t_perceptron init_perceptron(int amount):\n",
    "    srand(42)\n",
    "    cdef t_perceptron ret\n",
    "    ret.amount = amount\n",
    "    ret.weights = <double *>malloc(sizeof(double) * amount)\n",
    "#     ret.bias = <double>rand() / RAND_MAX\n",
    "    ret.bias = 0.27502931836911926\n",
    "    ret.weights[0] = 0.6394267984578837\n",
    "    ret.weights[1] = 0.025010755222666936\n",
    "#     for i in range(amount):\n",
    "#         ret.weights[i] = <double>rand() / RAND_MAX\n",
    "    return ret\n",
    "    \n",
    "cdef int quantizer(double value):\n",
    "    return 1 if value > 5.6 else 0\n",
    "    \n",
    "cdef list predict(t_perceptron *model, list data, int y):\n",
    "    cdef double rez = model.bias\n",
    "    for i in range(model.amount):\n",
    "        rez += data[i] * model.weights[i]\n",
    "    if y == -1:\n",
    "        return [quantizer(rez)]\n",
    "    cdef list ret = []\n",
    "    cdef double err\n",
    "    if rez != y:\n",
    "        err = y - rez\n",
    "        for i in range(model.amount):\n",
    "            ret.append(data[i] * err)\n",
    "        ret.append(err)\n",
    "    return ret\n",
    "\n",
    "cdef list train(t_perceptron *model, list data, list y, int epochs, double alpha):\n",
    "    cdef list ret = []\n",
    "    cdef unsigned long i = 0\n",
    "    cdef list delta\n",
    "    cdef double error = 1\n",
    "    if epochs == 0:\n",
    "        while (True):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "            i += 1\n",
    "            display(ret)\n",
    "        display(ret, final=True)\n",
    "    else:\n",
    "        for i in range(epochs):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            display(ret)\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "        display(ret, final=True)\n",
    "    return ret\n",
    "\n",
    "cdef t_perceptron model = init_perceptron(len(data[0]))\n",
    "train(&model, data, y_4_7, 1000000, 0.001)\n",
    "\n",
    "pred = [predict(&model, data[i], -1) for i in range(len(data))]\n",
    "      \n",
    "y = [1 if i == True else 0 for i in normalized_data_4_7['quality'] >= 7]\n",
    "\n",
    "print(sum([abs((y[i] - pred[i][0])) for i in range(len(y))]), '/', len(normalized_data_4_7))\n",
    "free(model.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It converges when data is separable in that hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's called a hyperplane. For 2-dimensional space it's a point, for 3-d it's line and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V.6 Marvin's rebuttal && bonus V.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\n",
    "from cpython cimport array\n",
    "import array\n",
    "\n",
    "pan_gal = pd.read_csv(\"./resources/resources/Pan Galactic Gargle Blaster.csv\", sep=';')\n",
    "\n",
    "y_4_7 = pan_gal['quality'].tolist()\n",
    "normalized_data_4_7 = data_4_7.copy()\n",
    "for column in normalized_data_4_7.columns:\n",
    "    if column != 'quality':\n",
    "        normalized_data_4_7[column] = (data_4_7[column] - min(data_4_7[column])) / (max(data_4_7[column]) - min(data_4_7[column]))\n",
    "data = normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values.tolist()\n",
    "        \n",
    "def process_to_poly(poly):\n",
    "    length = len(poly[0])\n",
    "    for line in poly:\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                line.append(line[i] * line[j])\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                for k in range(length):\n",
    "                    line.append(line[i] * line[j] * line[k])\n",
    "    print('Was:', length, 'Now:', len(poly[0]))\n",
    "    return poly\n",
    "\n",
    "data = process_to_poly(data)\n",
    "\n",
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        \n",
    "cdef struct s_perceptron:\n",
    "    double *weights;\n",
    "    double bias;\n",
    "    int amount;\n",
    "ctypedef s_perceptron t_perceptron\n",
    "\n",
    "cdef t_perceptron init_perceptron(int amount):\n",
    "    srand(42)\n",
    "    cdef t_perceptron ret\n",
    "    ret.amount = amount\n",
    "    ret.weights = <double *>malloc(sizeof(double) * amount)\n",
    "#     ret.bias = <double>rand() / RAND_MAX\n",
    "    ret.bias = 0.27502931836911926\n",
    "    ret.weights[0] = 0.6394267984578837\n",
    "    ret.weights[1] = 0.025010755222666936\n",
    "#     for i in range(amount):\n",
    "#         ret.weights[i] = <double>rand() / RAND_MAX\n",
    "    return ret\n",
    "    \n",
    "cdef int quantizer(double value):\n",
    "    return 1 if value > 5.6 else 0\n",
    "    \n",
    "cdef list predict(t_perceptron *model, list data, int y):\n",
    "    cdef double rez = model.bias\n",
    "    for i in range(model.amount):\n",
    "        rez += data[i] * model.weights[i]\n",
    "    if y == -1:\n",
    "        return [quantizer(rez)]\n",
    "    cdef list ret = []\n",
    "    cdef double err\n",
    "    if rez != y:\n",
    "        err = y - rez\n",
    "        for i in range(model.amount):\n",
    "            ret.append(data[i] * err)\n",
    "        ret.append(err)\n",
    "    return ret\n",
    "\n",
    "cdef list train(t_perceptron *model, list data, list y, int epochs, double alpha):\n",
    "    cdef list ret = []\n",
    "    cdef unsigned long i = 0\n",
    "    cdef list delta\n",
    "    cdef double error = 1\n",
    "    if epochs == 0:\n",
    "        while (True):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "            i += 1\n",
    "            display(ret)\n",
    "        display(ret, final=True)\n",
    "    else:\n",
    "        for i in range(epochs):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            display(ret)\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "        display(ret, final=True)\n",
    "    return ret\n",
    "\n",
    "cdef t_perceptron model = init_perceptron(len(data[0]))\n",
    "train(&model, data, y_4_7, 1000000, 0.001)\n",
    "\n",
    "pred = [predict(&model, data[i], -1) for i in range(len(data))]\n",
    "      \n",
    "y = [1 if i == True else 0 for i in normalized_data_4_7['quality'] >= 5]\n",
    "\n",
    "print(sum([abs((y[i] - pred[i][0])) for i in range(len(y))]), '/', len(normalized_data_4_7))\n",
    "      \n",
    "      \n",
    "free(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 10000, errors = 44.0\n",
      "....................................................................................................\n",
      "cycle = 20000, errors = 38.0\n",
      "....................................................................................................\n",
      "cycle = 30000, errors = 35.0\n",
      "....................................................................................................\n",
      "cycle = 40000, errors = 25.0\n",
      "....................................................................................................\n",
      "cycle = 50000, errors = 24.0\n",
      "....................................................................................................\n",
      "cycle = 60000, errors = 28.0\n",
      "....................................................................................................\n",
      "cycle = 70000, errors = 26.0\n",
      "....................................................................................................\n",
      "cycle = 80000, errors = 24.0\n",
      "....................................................................................................\n",
      "cycle = 90000, errors = 26.0\n",
      "...................................................................................................\n",
      "DONE\n",
      "cycle = 99999, errors = 26.0\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\n",
    "from cpython cimport array\n",
    "import array\n",
    "\n",
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')\n",
    "data_4_7 = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index()\n",
    "y = [1 if i == True else 0 for i in data_4_7['quality'] >= 7]\n",
    "normalized_data_4_7 = data_4_7.copy()\n",
    "for column in normalized_data_4_7.columns:\n",
    "    if column != 'quality':\n",
    "        normalized_data_4_7[column] = (data_4_7[column] - min(data_4_7[column])) / (max(data_4_7[column]) - min(data_4_7[column]))\n",
    "data = normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values.tolist()\n",
    "\n",
    "def process_to_poly(poly):\n",
    "    length = len(poly[0])\n",
    "    for line in poly:\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                line.append(line[i] * line[j])\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                for k in range(length):\n",
    "                    line.append(line[i] * line[j] * line[k])\n",
    "    print('Was:', length, 'Now:', len(poly[0]))\n",
    "    return poly\n",
    "\n",
    "# data = process_to_poly(data)\n",
    "\n",
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        \n",
    "cdef struct s_perceptron:\n",
    "    double *weights;\n",
    "    double bias;\n",
    "    int amount;\n",
    "ctypedef s_perceptron t_perceptron\n",
    "\n",
    "cdef t_perceptron init_perceptron(int amount):\n",
    "    srand(42)\n",
    "    cdef t_perceptron ret\n",
    "    ret.amount = amount\n",
    "    ret.weights = <double *>malloc(sizeof(double) * amount)\n",
    "    ret.bias = <double>rand() / RAND_MAX\n",
    "#     ret.bias = 0.27502931836911926\n",
    "#     ret.weights[0] = 0.6394267984578837\n",
    "#     ret.weights[1] = 0.025010755222666936\n",
    "    for i in range(amount):\n",
    "        ret.weights[i] = <double>rand() / RAND_MAX\n",
    "#         print('Weights[', i, '] = ', ret.weights[i], sep='')\n",
    "#     print('bias = ', ret.bias, '\\n')\n",
    "    return ret\n",
    "    \n",
    "cdef int activation(double value):\n",
    "    return 1 if value > 0 else 0\n",
    "    \n",
    "cdef double predict(t_perceptron *model, list data, double alpha, int y):\n",
    "    cdef double rez = model.bias\n",
    "    for i in range(model.amount):\n",
    "        rez += data[i] * model.weights[i]\n",
    "    rez = activation(rez)\n",
    "    if y == -1:\n",
    "        return rez\n",
    "    if rez != y:\n",
    "        for i in range(model.amount):\n",
    "            model.weights[i] += alpha * data[i] * (y - rez)\n",
    "        model.bias += alpha * (y - rez)\n",
    "    return rez != y\n",
    "\n",
    "cdef list train(t_perceptron model, list data, list y, int epochs, double alpha):\n",
    "    cdef list ret = []\n",
    "    cdef double errors = 1\n",
    "    cdef unsigned long i = 0\n",
    "    if epochs == 0:\n",
    "        while (errors):\n",
    "            errors = 0\n",
    "            for j, item in enumerate(data):\n",
    "                errors += predict(&model, item, alpha, y[j])\n",
    "            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias])\n",
    "            i += 1\n",
    "            display(ret)\n",
    "        display(ret, final=True)\n",
    "    else:\n",
    "        for i in range(epochs):\n",
    "            errors = 0\n",
    "            for j, item in enumerate(data):\n",
    "                errors += predict(&model, item, alpha, y[j])\n",
    "            ret.append([i, errors, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias])\n",
    "            display(ret)\n",
    "            if errors == 0:\n",
    "                break\n",
    "        display(ret, final=True)\n",
    "    return ret\n",
    "\n",
    "cdef t_perceptron model = init_perceptron(len(data[0]))\n",
    "train(model, data, y, 100000, 0.00001)\n",
    "free(model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 10000, errors = 343.0636037959219\n",
      "....................................................................................................\n",
      "cycle = 20000, errors = 309.90707869535083\n",
      "....................................................................................................\n",
      "cycle = 30000, errors = 292.60522723089235\n",
      "....................................................................................................\n",
      "cycle = 40000, errors = 281.6805991251494\n",
      "....................................................................................................\n",
      "cycle = 50000, errors = 273.79049565042914\n",
      "....................................................................................................\n",
      "cycle = 60000, errors = 267.630764373475\n",
      "....................................................................................................\n",
      "cycle = 70000, errors = 262.61589847789617\n",
      "....................................................................................................\n",
      "cycle = 80000, errors = 258.43552019919787\n",
      "....................................................................................................\n",
      "cycle = 90000, errors = 254.89822352578918\n",
      "....................................................................................................\n",
      "cycle = 100000, errors = 251.872545341132\n",
      "....................................................................................................\n",
      "cycle = 110000, errors = 249.26207520921002\n",
      "....................................................................................................\n",
      "cycle = 120000, errors = 246.9933515365013\n",
      "....................................................................................................\n",
      "cycle = 130000, errors = 245.00905373943763\n",
      "....................................................................................................\n",
      "cycle = 140000, errors = 243.26370485816113\n",
      "....................................................................................................\n",
      "cycle = 150000, errors = 241.72074629376937\n",
      "....................................................................................................\n",
      "cycle = 160000, errors = 240.35045539519055\n",
      "....................................................................................................\n",
      "cycle = 170000, errors = 239.12842285539446\n",
      "....................................................................................................\n",
      "cycle = 180000, errors = 238.03441961573887\n",
      "....................................................................................................\n",
      "cycle = 190000, errors = 237.0515422265768\n",
      "....................................................................................................\n",
      "cycle = 200000, errors = 236.16556068480256\n",
      "....................................................................................................\n",
      "cycle = 210000, errors = 235.36441531948265\n",
      "....................................................................................................\n",
      "cycle = 220000, errors = 234.63782453409655\n",
      "....................................................................................................\n",
      "cycle = 230000, errors = 233.97697580178007\n",
      "....................................................................................................\n",
      "cycle = 240000, errors = 233.37427978600545\n",
      "....................................................................................................\n",
      "cycle = 250000, errors = 232.82317279161109\n",
      "....................................................................................................\n",
      "cycle = 260000, errors = 232.3179565832832\n",
      "....................................................................................................\n",
      "cycle = 270000, errors = 231.853667380617\n",
      "....................................................................................................\n",
      "cycle = 280000, errors = 231.42596785690344\n",
      "....................................................................................................\n",
      "cycle = 290000, errors = 231.03105744764517\n",
      "....................................................................................................\n",
      "cycle = 300000, errors = 230.6655973662468\n",
      "....................................................................................................\n",
      "cycle = 310000, errors = 230.3266475359341\n",
      "....................................................................................................\n",
      "cycle = 320000, errors = 230.01161325532826\n",
      "....................................................................................................\n",
      "cycle = 330000, errors = 229.7181998750094\n",
      "....................................................................................................\n",
      "cycle = 340000, errors = 229.44437411310224\n",
      "....................................................................................................\n",
      "cycle = 350000, errors = 229.18833090778008\n",
      "....................................................................................................\n",
      "cycle = 360000, errors = 228.94846491409155\n",
      "....................................................................................................\n",
      "cycle = 370000, errors = 228.7233459166626\n",
      "....................................................................................................\n",
      "cycle = 380000, errors = 228.51169755955527\n",
      "....................................................................................................\n",
      "cycle = 390000, errors = 228.31237889796697\n",
      "....................................................................................................\n",
      "cycle = 400000, errors = 228.12436835955327\n",
      "....................................................................................................\n",
      "cycle = 410000, errors = 227.94674977044826\n",
      "....................................................................................................\n",
      "cycle = 420000, errors = 227.77870015592967\n",
      "....................................................................................................\n",
      "cycle = 430000, errors = 227.61947907074455\n",
      "....................................................................................................\n",
      "cycle = 440000, errors = 227.4684192513185\n",
      "....................................................................................................\n",
      "cycle = 450000, errors = 227.32491841300336\n",
      "....................................................................................................\n",
      "cycle = 460000, errors = 227.1884320413153\n",
      "....................................................................................................\n",
      "cycle = 470000, errors = 227.05846704778153\n",
      "....................................................................................................\n",
      "cycle = 480000, errors = 226.93457617925233\n",
      "....................................................................................................\n",
      "cycle = 490000, errors = 226.8163530849497\n",
      "....................................................................................................\n",
      "cycle = 500000, errors = 226.70342795862226\n",
      "....................................................................................................\n",
      "cycle = 510000, errors = 226.59546368432012\n",
      "....................................................................................................\n",
      "cycle = 520000, errors = 226.49215242380535\n",
      "....................................................................................................\n",
      "cycle = 530000, errors = 226.39321259177729\n",
      "....................................................................................................\n",
      "cycle = 540000, errors = 226.29838617207443\n",
      "....................................................................................................\n",
      "cycle = 550000, errors = 226.20743633402995\n",
      "....................................................................................................\n",
      "cycle = 560000, errors = 226.12014531335186\n",
      "....................................................................................................\n",
      "cycle = 570000, errors = 226.0363125263795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................\n",
      "cycle = 580000, errors = 225.95575289044297\n",
      "....................................................................................................\n",
      "cycle = 590000, errors = 225.87829532642638\n",
      "....................................................................................................\n",
      "cycle = 600000, errors = 225.80378142255256\n",
      "....................................................................................................\n",
      "cycle = 610000, errors = 225.7320642409571\n",
      "....................................................................................................\n",
      "cycle = 620000, errors = 225.66300725083045\n",
      "....................................................................................................\n",
      "cycle = 630000, errors = 225.59648337384974\n",
      "....................................................................................................\n",
      "cycle = 640000, errors = 225.53237412930847\n",
      "....................................................................................................\n",
      "cycle = 650000, errors = 225.47056886783443\n",
      "....................................................................................................\n",
      "cycle = 660000, errors = 225.41096408388307\n",
      "....................................................................................................\n",
      "cycle = 670000, errors = 225.3534627983372\n",
      "....................................................................................................\n",
      "cycle = 680000, errors = 225.29797400353064\n",
      "....................................................................................................\n",
      "cycle = 690000, errors = 225.2444121639107\n",
      "....................................................................................................\n",
      "cycle = 700000, errors = 225.19269676631174\n",
      "....................................................................................................\n",
      "cycle = 710000, errors = 225.14275191450474\n",
      "....................................................................................................\n",
      "cycle = 720000, errors = 225.09450596328315\n",
      "....................................................................................................\n",
      "cycle = 730000, errors = 225.0478911878803\n",
      "....................................................................................................\n",
      "cycle = 740000, errors = 225.0028434849792\n",
      "....................................................................................................\n",
      "cycle = 750000, errors = 224.95930210199228\n",
      "....................................................................................................\n",
      "cycle = 760000, errors = 224.91720939165498\n",
      "....................................................................................................\n",
      "cycle = 770000, errors = 224.87651058929907\n",
      "....................................................................................................\n",
      "cycle = 780000, errors = 224.83715361046836\n",
      "....................................................................................................\n",
      "cycle = 790000, errors = 224.79908886677936\n",
      "....................................................................................................\n",
      "cycle = 800000, errors = 224.76226909817362\n",
      "....................................................................................................\n",
      "cycle = 810000, errors = 224.726649219895\n",
      "....................................................................................................\n",
      "cycle = 820000, errors = 224.69218618271105\n",
      "....................................................................................................\n",
      "cycle = 830000, errors = 224.6588388450556\n",
      "....................................................................................................\n",
      "cycle = 840000, errors = 224.626567855908\n",
      "....................................................................................................\n",
      "cycle = 850000, errors = 224.59533554735322\n",
      "....................................................................................................\n",
      "cycle = 860000, errors = 224.56510583587462\n",
      "....................................................................................................\n",
      "cycle = 870000, errors = 224.53584413154059\n",
      "....................................................................................................\n",
      "cycle = 880000, errors = 224.50751725431556\n",
      "....................................................................................................\n",
      "cycle = 890000, errors = 224.4800933568271\n",
      "....................................................................................................\n",
      "cycle = 900000, errors = 224.45354185297703\n",
      "....................................................................................................\n",
      "cycle = 910000, errors = 224.42783335185226\n",
      "....................................................................................................\n",
      "cycle = 920000, errors = 224.40293959644333\n",
      "....................................................................................................\n",
      "cycle = 930000, errors = 224.3788334067347\n",
      "....................................................................................................\n",
      "cycle = 940000, errors = 224.35548862677248\n",
      "....................................................................................................\n",
      "cycle = 950000, errors = 224.33288007535\n",
      "....................................................................................................\n",
      "cycle = 960000, errors = 224.31098350000016\n",
      "....................................................................................................\n",
      "cycle = 970000, errors = 224.2897755339974\n",
      "....................................................................................................\n",
      "cycle = 980000, errors = 224.26923365612362\n",
      "....................................................................................................\n",
      "cycle = 990000, errors = 224.24933615295132\n",
      "...................................................................................................\n",
      "DONE\n",
      "cycle = 999999, errors = 224.2300639803609\n",
      "28 / 280\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "import pandas as pd\n",
    "from libc.stdlib cimport malloc, free, rand, srand, RAND_MAX\n",
    "from cpython cimport array\n",
    "import array\n",
    "\n",
    "red_wine = pd.read_csv(\"./resources/resources/winequality-red.csv\", sep=';')\n",
    "\n",
    "data_4_7 = red_wine[(red_wine['quality'] >= 7) | (red_wine['quality'] <= 4)].reset_index()\n",
    "y_4_7 = data_4_7['quality'].tolist()\n",
    "normalized_data_4_7 = data_4_7.copy()\n",
    "for column in normalized_data_4_7.columns:\n",
    "    if column != 'quality':\n",
    "        normalized_data_4_7[column] = (data_4_7[column] - min(data_4_7[column])) / (max(data_4_7[column]) - min(data_4_7[column]))\n",
    "data = normalized_data_4_7[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']].values.tolist()\n",
    "        \n",
    "def process_to_poly(poly):\n",
    "    length = len(poly[0])\n",
    "    for line in poly:\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                line.append(line[i] * line[j])\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                for k in range(length):\n",
    "                    line.append(line[i] * line[j] * line[k])\n",
    "    print('Was:', length, 'Now:', len(poly[0]))\n",
    "    return poly\n",
    "\n",
    "# data = process_to_poly(data)\n",
    "\n",
    "def display(ret, dot=100, detail=10000, final=False):\n",
    "    \"\"\"Displays text info about training process\"\"\"\n",
    "    if final:\n",
    "        print()\n",
    "        print('DONE')\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "    if ret[-1][0] == 0:\n",
    "        return\n",
    "    if ret[-1][0] % dot == 0:\n",
    "        print('.', end='')\n",
    "    if ret[-1][0] % detail == 0:\n",
    "        print()\n",
    "        print('cycle = ', ret[-1][0], ', errors = ', ret[-1][1], sep='')\n",
    "        \n",
    "cdef struct s_perceptron:\n",
    "    double *weights;\n",
    "    double bias;\n",
    "    int amount;\n",
    "ctypedef s_perceptron t_perceptron\n",
    "\n",
    "cdef t_perceptron init_perceptron(int amount):\n",
    "    srand(42)\n",
    "    cdef t_perceptron ret\n",
    "    ret.amount = amount\n",
    "    ret.weights = <double *>malloc(sizeof(double) * amount)\n",
    "#     ret.bias = <double>rand() / RAND_MAX\n",
    "    ret.bias = 0.27502931836911926\n",
    "    ret.weights[0] = 0.6394267984578837\n",
    "    ret.weights[1] = 0.025010755222666936\n",
    "#     for i in range(amount):\n",
    "#         ret.weights[i] = <double>rand() / RAND_MAX\n",
    "    return ret\n",
    "    \n",
    "cdef int quantizer(double value):\n",
    "    return 1 if value > 5.6 else 0\n",
    "    \n",
    "cdef list predict(t_perceptron *model, list data, int y):\n",
    "    cdef double rez = model.bias\n",
    "    for i in range(model.amount):\n",
    "        rez += data[i] * model.weights[i]\n",
    "    if y == -1:\n",
    "        return [quantizer(rez)]\n",
    "    cdef list ret = []\n",
    "    cdef double err\n",
    "    if rez != y:\n",
    "        err = y - rez\n",
    "        for i in range(model.amount):\n",
    "            ret.append(data[i] * err)\n",
    "        ret.append(err)\n",
    "    return ret\n",
    "\n",
    "cdef list train(t_perceptron *model, list data, list y, int epochs, double alpha):\n",
    "    cdef list ret = []\n",
    "    cdef unsigned long i = 0\n",
    "    cdef list delta\n",
    "    cdef double error = 1\n",
    "    if epochs == 0:\n",
    "        while (True):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "            i += 1\n",
    "            display(ret)\n",
    "        display(ret, final=True)\n",
    "    else:\n",
    "        for i in range(epochs):\n",
    "            error = 0\n",
    "            delta = [0] * (model.amount + 1)\n",
    "            for j, item in enumerate(data):\n",
    "                rez = predict(model, item, y[j])\n",
    "                for k in range(model.amount + 1):\n",
    "                    delta[k] += rez[k]\n",
    "                error += rez[-1] ** 2\n",
    "            for k in range(model.amount):\n",
    "                model.weights[k] += alpha * delta[k] / len(data)\n",
    "            model.bias += alpha * delta[-1] / len(data)\n",
    "            ret.append([i, error, [model.weights[i] for i in range(model.amount)],\n",
    "                        model.bias - 5.6])\n",
    "            display(ret)\n",
    "            if i > 0 and abs(ret[-2][1] - error) < 0.0000000001:\n",
    "                break\n",
    "        display(ret, final=True)\n",
    "    return ret\n",
    "\n",
    "cdef t_perceptron model = init_perceptron(len(data[0]))\n",
    "train(&model, data, y_4_7, 1000000, 0.001)\n",
    "\n",
    "pred = [predict(&model, data[i], -1) for i in range(len(data))]\n",
    "      \n",
    "y = [1 if i == True else 0 for i in normalized_data_4_7['quality'] >= 7]\n",
    "\n",
    "print(sum([abs((y[i] - pred[i][0])) for i in range(len(y))]), '/', len(normalized_data_4_7))\n",
    "      \n",
    "      \n",
    "free(model.weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
